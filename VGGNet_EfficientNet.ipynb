{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3694b503",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8a1849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.9.0+cu111\n",
      "Timm: 0.4.5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import timm\n",
    "from timm.data import create_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet101, mobilenet_v2\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision\n",
    "import wandb\n",
    "from ulid import ULID\n",
    "\n",
    "\n",
    "from robust_optimization import RobustOptimizer\n",
    "\n",
    "print(f'Torch: {torch.__version__}')\n",
    "print(f'Timm: {timm.__version__}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4b53da8",
   "metadata": {},
   "source": [
    "### Select Network and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63aef03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chooseModels = {\n",
    "    \"efficientNet\": \"efficientnet_b0\",\n",
    "    \"vgg19\": \"vgg19\",\n",
    "    \"efficientNet2\":\"efficientnet_b2\"\n",
    "}\n",
    "chooseDatasets = {\n",
    "    \"downScaled affecnet-folder\": \"downScaled_folder_name\",\n",
    "    \"downScaled affecnet-label\": \"downScaled_label_name\",\n",
    "    \"highRes affecnet-folder\": \"kaggle_highresAffecnet\",\n",
    "    \"FER\":\"FER\"\n",
    "}\n",
    "chooseLoss = {\n",
    "    \"weighted\": \"weightedLoss\",\n",
    "    \"arcface\":\"arcface\"\n",
    "}\n",
    "chooseMLP = {\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3\n",
    "}\n",
    "\n",
    "\n",
    "backbone = chooseModels[\"efficientNet2\"]\n",
    "dataset_used = chooseDatasets[\"highRes affecnet-folder\"]\n",
    "loss_used = chooseLoss[\"weighted\"]\n",
    "MLP_used = chooseMLP[1]\n",
    "\n",
    "\n",
    "# CHANGE IF DIRECTORY NAMES ARE DIFFERENT\n",
    "lowResData = \"./DownScaledAffectNet/\"\n",
    "highResData = \"./AffectNet/\"\n",
    "FerData = \"./FER-2013/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5d08ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5orq1jpd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">./kaggle_highresAffecnet_efficientnet_b2_mlp1_1686449532946</strong> at: <a href='https://wandb.ai/consolebot/252D_emotion_rec/runs/5orq1jpd' target=\"_blank\">https://wandb.ai/consolebot/252D_emotion_rec/runs/5orq1jpd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230610_191214-5orq1jpd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5orq1jpd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67bc79841924033b73af45887c9a2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666870224289596, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jjhaveri/wandb/run-20230610_191353-lxhbd9rq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/consolebot/252D_emotion_rec/runs/lxhbd9rq' target=\"_blank\">./kaggle_highresAffecnet_efficientnet_b2_mlp1_1686449633636</a></strong> to <a href='https://wandb.ai/consolebot/252D_emotion_rec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/consolebot/252D_emotion_rec' target=\"_blank\">https://wandb.ai/consolebot/252D_emotion_rec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/consolebot/252D_emotion_rec/runs/lxhbd9rq' target=\"_blank\">https://wandb.ai/consolebot/252D_emotion_rec/runs/lxhbd9rq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/consolebot/252D_emotion_rec/runs/lxhbd9rq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff1299ae940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIQUE_RUN_ID = str(ULID().milliseconds)\n",
    "wandb.init(project=\"252D_emotion_rec\", entity='consolebot', name = f'./{dataset_used}_{backbone}_mlp{MLP_used}_{UNIQUE_RUN_ID}',   config={\n",
    "    \"backbone\": backbone,\n",
    "    \"dataset_used\": dataset_used,\n",
    "    \"loss_used\": loss_used,\n",
    "    \"epochs\": 10,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6cdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(t_loss, v_loss):\n",
    "    fname = f'./runs/{UNIQUE_RUN_ID}_loss_plot.png'\n",
    "    \n",
    "    epochs = range(1, len(t_loss) + 1)\n",
    "\n",
    "    # Plot generator and discriminator losses\n",
    "    plt.plot(epochs, t_loss, label='Train Loss')\n",
    "    plt.plot(epochs, v_loss, label='Valid Loss')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train and Valid Losses')\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(fname)\n",
    "    wandb.log({\"loss_plot\": wandb.Image(fname)})\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecf54e5b",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56b5a130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16 #48# 32# 32 #16 #8 #\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8734ed41",
   "metadata": {},
   "source": [
    "## Transforms on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec274324",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=260 if 'b2' in backbone else 224 # 300 # 80 #\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "# print(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "106db0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_workers = no of cpu cores - 1\n",
    "kwargs = {'num_workers': 7, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe413a7d",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8388ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_used == \"downScaled_folder_name\":\n",
    "    affectnet_dir = lowResData\n",
    "    class AffectNet(data.Dataset):\n",
    "        def __init__(self, aff_path, mode, use_cache=True, transforms=None, force=False):\n",
    "            self.mode = mode\n",
    "            self.transforms = transforms\n",
    "            self.aff_path = aff_path\n",
    "            self.base_path = aff_path\n",
    "\n",
    "            if mode == \"train\": \n",
    "                df = pd.read_csv('lowres_noise_train_labels.csv')\n",
    "            elif mode == \"test\":\n",
    "                df = pd.read_csv('lowres_noise_labels.csv')\n",
    "\n",
    "            self.data = df \n",
    "            self.file_paths = self.data.loc[:, 'pth'].values\n",
    "            self.label = self.data.loc[:, 'label'].values\n",
    "            self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "            sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "            self.dick = { 'neutral' :0 ,'happy' : 1, 'sad' :2 , 'surprise':3, 'fear':4, 'disgust':5, 'anger':6, 'contempt':7}\n",
    "            for l, c in zip(sample_label, sample_counts):\n",
    "                print(f'{self.emotion_labels[self.dick[l.lower()]]}: {c} ', end='')\n",
    "            print(f'\\n{len(self)} images')\n",
    "\n",
    "\n",
    "        def get_weight(self):\n",
    "            self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "            self.class_to_idx = {}\n",
    "            self.idx_to_class = {}\n",
    "            for i, emotion in enumerate(self.emotion_labels):\n",
    "                self.class_to_idx[emotion] = i\n",
    "                self.idx_to_class[i] = emotion\n",
    "            sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "            for l, c in zip(sample_label, sample_counts):\n",
    "                print(f'{self.emotion_labels[self.dick[l.lower()]]}: {c} ', end='')\n",
    "            print('')\n",
    "\n",
    "            cw = 1/sample_counts\n",
    "            cw /= cw.min()\n",
    "            class_weights = {self.dick[i.lower()]:cwi for i, cwi in zip(sample_label, cw)}\n",
    "            print(class_weights)\n",
    "            return class_weights\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            path = os.path.join(self.base_path, self.file_paths[idx])\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            label = self.label[idx]\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)\n",
    "\n",
    "            return image, self.dick[label]\n",
    "\n",
    "elif dataset_used == \"downScaled_label_name\":\n",
    "    affectnet_dir = lowResData\n",
    "    class AffectNet(data.Dataset):\n",
    "        def __init__(self, aff_path, mode, use_cache=True, transforms=None, force=False):\n",
    "            self.mode = mode\n",
    "            self.transforms = transforms\n",
    "            self.aff_path = aff_path\n",
    "            self.base_path = aff_path\n",
    "\n",
    "            if mode == \"train\": \n",
    "                df = pd.read_csv('lowres_noiseFree_train_labels.csv')\n",
    "            elif mode == \"test\":\n",
    "                df = pd.read_csv('lowres_noiseFree_test_labels.csv')\n",
    "\n",
    "            self.data = df \n",
    "            self.file_paths = self.data.loc[:, 'pth'].values\n",
    "            self.label = self.data.loc[:, 'label'].values\n",
    "            self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "            sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "            self.dick = { 'neutral' :0 ,'happy' : 1, 'sad' :2 , 'surprise':3, 'fear':4, 'disgust':5, 'anger':6, 'contempt':7}\n",
    "            for l, c in zip(sample_label, sample_counts):\n",
    "                print(f'{self.emotion_labels[self.dick[l.lower()]]}: {c} ', end='')\n",
    "            print(f'\\n{len(self)} images')\n",
    "\n",
    "\n",
    "        def get_weight(self):\n",
    "            self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "            self.class_to_idx = {}\n",
    "            self.idx_to_class = {}\n",
    "            for i, emotion in enumerate(self.emotion_labels):\n",
    "                self.class_to_idx[emotion] = i\n",
    "                self.idx_to_class[i] = emotion\n",
    "            sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "            for l, c in zip(sample_label, sample_counts):\n",
    "                print(f'{self.emotion_labels[self.dick[l.lower()]]}: {c} ', end='')\n",
    "            print('')\n",
    "\n",
    "            cw = 1/sample_counts\n",
    "            cw /= cw.min()\n",
    "            class_weights = {self.dick[i.lower()]:cwi for i, cwi in zip(sample_label, cw)}\n",
    "            print(class_weights)\n",
    "            return class_weights\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            path = os.path.join(self.base_path, self.file_paths[idx])\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            label = self.label[idx]\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)\n",
    "\n",
    "            return image, self.dick[label]\n",
    "\n",
    "elif dataset_used == \"kaggle_highresAffecnet\":\n",
    "    affectnet_dir = highResData\n",
    "    class AffectNet(data.Dataset):\n",
    "        def __init__(self, aff_path, mode, use_cache=True, transforms=None, force=False):\n",
    "            self.mode = mode\n",
    "            self.transforms = transforms\n",
    "            self.aff_path = aff_path\n",
    "            self.base_path = aff_path\n",
    "\n",
    "            if mode == \"train\": \n",
    "                df = pd.read_csv('highRes_train_labels.csv')\n",
    "            elif mode == \"test\":\n",
    "                df = pd.read_csv('highRes_test_labels.csv')\n",
    "\n",
    "            self.data = df \n",
    "            self.file_paths = self.data.loc[:, 'pth'].values\n",
    "            self.label = self.data.loc[:, 'label'].values\n",
    "            self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "            sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "            self.dick = { 'neutral' :0 ,'happy' : 1, 'sad' :2 , 'surprise':3, 'fear':4, 'disgust':5, 'anger':6, 'contempt':7}\n",
    "            for l, c in zip(sample_label, sample_counts):\n",
    "                print(f'{self.emotion_labels[self.dick[l.lower()]]}: {c} ', end='')\n",
    "            print(f'\\n{len(self)} images')\n",
    "\n",
    "\n",
    "        def get_weight(self):\n",
    "            self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "            self.class_to_idx = {}\n",
    "            self.idx_to_class = {}\n",
    "            for i, emotion in enumerate(self.emotion_labels):\n",
    "                self.class_to_idx[emotion] = i\n",
    "                self.idx_to_class[i] = emotion\n",
    "            sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "            for l, c in zip(sample_label, sample_counts):\n",
    "                print(f'{self.emotion_labels[self.dick[l.lower()]]}: {c} ', end='')\n",
    "            print('')\n",
    "\n",
    "            cw = 1/sample_counts\n",
    "            cw /= cw.min()\n",
    "            class_weights = {self.dick[i.lower()]:cwi for i, cwi in zip(sample_label, cw)}\n",
    "            print(class_weights)\n",
    "            return class_weights\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            yo = self.file_paths[idx]\n",
    "    #         yo = yo[12:]\n",
    "    #         print(\"yo\")\n",
    "            path = os.path.join(self.base_path, yo[2:])\n",
    "    #         print(path,\"path\")\n",
    "    #         print(\"\\n\")\n",
    "    #         print(\"base\",self.base_path)\n",
    "    #         print(\"\\n\")\n",
    "    #         print(\"file\",self.file_paths[idx])\n",
    "    #         print(\"\\n\")\n",
    "    #         assert 1!=1\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            label = self.label[idx]\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image)\n",
    "\n",
    "            return image, self.dick[label]\n",
    "elif dataset_used == \"FER\":\n",
    "    affectnet_dir = FerData\n",
    "    trainset = create_dataset(name='', root='./Data_FER/train', transform=train_transforms)\n",
    "    valset = create_dataset(name='', root='./Data_FER/test', transform=test_transforms)\n",
    "else:\n",
    "    import sys\n",
    "    sys.exit(\"Dataset not Defined!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9479d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger: 3200 Contempt: 3000 Disgust: 3042 Fear: 3200 Happiness: 3200 Neutral: 3200 Sadness: 3200 Surprise: 3200 \n",
      "25242 images\n",
      "Anger: 800 Contempt: 750 Disgust: 761 Fear: 800 Happiness: 800 Neutral: 800 Sadness: 800 Surprise: 800 \n",
      "6311 images\n"
     ]
    }
   ],
   "source": [
    "if dataset_used != \"FER\":\n",
    "    trainset = AffectNet(affectnet_dir, 'train', transforms=train_transforms, force=False)\n",
    "    valset = AffectNet(affectnet_dir, 'test', transforms=test_transforms)\n",
    "trainloader = data.DataLoader(trainset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "valloader = data.DataLoader(valset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec894bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger: 3200 Contempt: 3000 Disgust: 3042 Fear: 3200 Happiness: 3200 Neutral: 3200 Sadness: 3200 Surprise: 3200 \n",
      "{6: 1.0, 7: 1.0666666666666667, 5: 1.051939513477975, 4: 1.0, 1: 1.0, 0: 1.0, 2: 1.0, 3: 1.0}\n"
     ]
    }
   ],
   "source": [
    "if dataset_used != \"FER\":\n",
    "    class_weights = trainset.get_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "308d7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "def set_parameter_requires_grad(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "494e6058",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de62002f",
   "metadata": {},
   "source": [
    "### Weighted Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "369ae943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runing on  cuda\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "def get_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(\"runing on \", device)\n",
    "if dataset_used != \"FER\":\n",
    "    weights = torch.FloatTensor(list(class_weights.values())).to(device)\n",
    "\n",
    "def label_smooth(target, n_classes: int, label_smoothing=0.1):\n",
    "    # convert to one-hot\n",
    "    batch_size = target.size(0)\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    soft_target = torch.zeros((batch_size, n_classes), device=target.device)\n",
    "    soft_target.scatter_(1, target, 1)\n",
    "    # label smoothing\n",
    "    soft_target = soft_target * (1 - label_smoothing) + label_smoothing / n_classes\n",
    "    return soft_target\n",
    "\n",
    "def cross_entropy_loss_with_soft_target(pred, soft_target):\n",
    "    #logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "    return torch.mean(torch.sum(- weights*soft_target * torch.nn.functional.log_softmax(pred, -1), 1))\n",
    "\n",
    "def cross_entropy_with_label_smoothing(pred, target):\n",
    "    soft_target = label_smooth(target, pred.size(1)) #num_classes) #\n",
    "    return cross_entropy_loss_with_soft_target(pred, soft_target)\n",
    "\n",
    "if dataset_used != \"FER\":\n",
    "    criterion=cross_entropy_with_label_smoothing\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32c8e3f",
   "metadata": {},
   "source": [
    "### Arcface Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d54ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ArcFaceLoss(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_size, margin, scale):\n",
    "        \"\"\"\n",
    "        ArcFace: Additive Angular Margin Loss for Deep Face Recognition\n",
    "        (https://arxiv.org/pdf/1801.07698.pdf)\n",
    "        Args:\n",
    "            num_classes: The number of classes in your training dataset\n",
    "            embedding_size: The size of the embeddings that you pass into\n",
    "            margin: m in the paper, the angular margin penalty in radians\n",
    "            scale: s in the paper, feature scale\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.margin = margin\n",
    "        self.scale = scale\n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.Tensor(num_classes, embedding_size)).to(device)\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            loss: scalar\n",
    "        \"\"\"\n",
    "        cosine = self.get_cosine(embeddings) # (None, n_classes)\n",
    "        mask = self.get_target_mask(labels) # (None, n_classes)\n",
    "        cosine_of_target_classes = cosine[mask == 1] # (None, )\n",
    "        modified_cosine_of_target_classes = self.modify_cosine_of_target_classes(\n",
    "            cosine_of_target_classes\n",
    "        ) # (None, )\n",
    "        diff = (modified_cosine_of_target_classes - cosine_of_target_classes).unsqueeze(1) # (None,1)\n",
    "        logits = cosine + (mask * diff) # (None, n_classes)\n",
    "        logits = self.scale_logits(logits) # (None, n_classes)\n",
    "        return nn.CrossEntropyLoss()(logits, labels)\n",
    "        \n",
    "    def get_cosine(self, embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (None, embedding_size)\n",
    "        Returns:\n",
    "            cosine: (None, n_classes)\n",
    "        \"\"\"\n",
    "#         self.W = self.W.to(device)\n",
    "#         print(embeddings.device,self.W.device,\"yo\")\n",
    "        cosine = F.linear(F.normalize(embeddings), F.normalize(self.W))\n",
    "        return cosine\n",
    "    \n",
    "    def get_target_mask(self, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels: (None,)\n",
    "        Returns:\n",
    "            mask: (None, n_classes)\n",
    "        \"\"\"\n",
    "        batch_size = labels.size(0)\n",
    "        onehot = torch.zeros(batch_size, self.num_classes, device=labels.device)\n",
    "        onehot.scatter_(1, labels.unsqueeze(-1), 1)\n",
    "        return onehot\n",
    "        \n",
    "    def modify_cosine_of_target_classes(self, cosine_of_target_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cosine_of_target_classes: (None,)\n",
    "        Returns:\n",
    "            modified_cosine_of_target_classes: (None,)\n",
    "        \"\"\"\n",
    "        eps = 1e-6\n",
    "        # theta in the paper\n",
    "        angles = torch.acos(torch.clamp(cosine_of_target_classes, -1 + eps, 1 - eps))\n",
    "        return torch.cos(angles + self.margin)\n",
    "    \n",
    "    def scale_logits(self, logits):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: (None, n_classes)\n",
    "        Returns:\n",
    "            scaled_logits: (None, n_classes)\n",
    "        \"\"\"\n",
    "        return logits * self.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b472223",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface = ArcFaceLoss(\n",
    "                num_classes=8, \n",
    "                embedding_size=8,\n",
    "                margin=0.3, \n",
    "                scale=30.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "066063a0",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1dafa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,n_epochs=100, learningrate=lr, robust=False):\n",
    "    # optimizer\n",
    "\n",
    "    if robust:\n",
    "        optimizer = RobustOptimizer(filter(lambda p: p.requires_grad, model.parameters()), optim.Adam, lr=learningrate)\n",
    "        #print(optimizer)\n",
    "    else:\n",
    "        optimizer=optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learningrate)\n",
    "    # scheduler\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    best_acc=0\n",
    "    best_model=None\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        model.train()\n",
    "        for data, label in tqdm(trainloader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "#             print(\"data\",data.shape)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "#             print(output.device)\n",
    "#             print(label.device)\n",
    "            \n",
    "            if loss_used == \"arcface\":\n",
    "                loss = arcface(output, label)\n",
    "            else:\n",
    "                loss = criterion(output, label)\n",
    "\n",
    "            if robust:\n",
    "                #optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "  \n",
    "                # second forward-backward pass\n",
    "                output = model(data)\n",
    "                output = output.to(device)\n",
    "                if loss_used == \"arcface\":\n",
    "                    loss = arcface(output, label)\n",
    "                else:\n",
    "                    loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == label).float().sum()\n",
    "            epoch_accuracy += acc\n",
    "            epoch_loss += loss\n",
    "        epoch_accuracy /= len(trainset)\n",
    "        epoch_loss /= len(trainset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            for data, label in valloader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "#                 val_output = val_output.to(device)\n",
    "\n",
    "                val_output = model(data)\n",
    "                if loss_used == \"arcface\":\n",
    "                    val_loss = arcface(val_output, label)\n",
    "                else:\n",
    "                    val_loss = criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output.argmax(dim=1) == label).float().sum()\n",
    "                epoch_val_accuracy += acc\n",
    "                epoch_val_loss += val_loss\n",
    "        epoch_val_accuracy /= len(valset)\n",
    "        epoch_val_loss /= len(valset)\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        \n",
    "        wandb.log({'epoch': epoch+1, 'Train Loss': epoch_loss, 'Validation Loss': epoch_val_loss, 'Validation Accuracy': epoch_val_accuracy})\n",
    "        train_lossi.append(epoch_loss.item())\n",
    "        val_lossi.append(epoch_val_loss.item())\n",
    "        \n",
    "        if best_acc<epoch_val_accuracy:\n",
    "            best_acc=epoch_val_accuracy\n",
    "            best_model=copy.deepcopy(model.state_dict())\n",
    "        #scheduler.step()\n",
    "    \n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "        print(f\"Best acc:{best_acc}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            for data, label in valloader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                val_output = model(data)\n",
    "                if loss_used == \"arcface\":\n",
    "                    val_loss = arcface(val_output, label)\n",
    "                else:\n",
    "                    val_loss = criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output.argmax(dim=1) == label).float().sum()\n",
    "                epoch_val_accuracy += acc\n",
    "                epoch_val_loss += val_loss\n",
    "        epoch_val_accuracy /= len(valset)\n",
    "        epoch_val_loss /= len(valset)\n",
    "        print(\n",
    "            f\"val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No best model Best acc:{best_acc}\")\n",
    "    \n",
    "    plot_loss(train_lossi, val_lossi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37cc8c0e",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06753fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backbone == \"vgg19\":\n",
    "    model = torchvision.models.vgg19(pretrained=True)\n",
    "    in_feat = 25088\n",
    "    \n",
    "elif backbone == \"efficientnet_b0\":\n",
    "    model = timm.create_model('tf_efficientnet_b0_ns', pretrained=False)\n",
    "    model.classifier=torch.nn.Identity()\n",
    "    model.load_state_dict(torch.load('./state_vggface2_enet0_new.pt', map_location=torch.device(device))) #_new\n",
    "    in_feat = 1280 \n",
    "elif backbone == \"efficientnet_b2\":\n",
    "    model = timm.create_model('tf_efficientnet_b2_ns', pretrained=False)\n",
    "    model.classifier=torch.nn.Identity()\n",
    "    model.load_state_dict(torch.load('./state_vggface2_enet2.pt', map_location=torch.device(device))) #_new\n",
    "    in_feat = 1408 \n",
    "else:\n",
    "    import sys\n",
    "    sys.exit(\"INVALID model,, NOT IMPLEMENTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93f31431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n",
      "        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
      "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
      "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
      "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
      "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
      "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
      "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
      "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2dSame(720, 720, kernel_size=(5, 5), stride=(2, 2), groups=720, bias=False)\n",
      "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
      "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
      "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SiLU(inplace=True)\n",
      "        (conv_dw): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
      "        (bn2): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SiLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1408, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): SiLU(inplace=True)\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1408, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if dataset_used != \"FER\":\n",
    "    num_classes = len(trainset.emotion_labels)\n",
    "else:\n",
    "    num_classes = 8\n",
    "\n",
    "if backbone == \"vgg19\":\n",
    "    if MLP_used == 3:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=10000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=10000, out_features=1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1000, out_features=num_classes)\n",
    "        )\n",
    "    elif MLP_used == 2:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=10000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=10000, out_features=num_classes),\n",
    "        )\n",
    "    elif MLP_used == 1:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=num_classes),\n",
    "        )\n",
    "    else:\n",
    "        import sys\n",
    "        sys.exit(\"INVALID number of layers in MLP,, NOT IMPLEMENTED\")\n",
    "\n",
    "       \n",
    "    \n",
    "if backbone == \"efficientnet_b0\":\n",
    "    if MLP_used == 3:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=512, out_features=num_classes)\n",
    "        )\n",
    "    elif MLP_used == 2:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=640),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=640, out_features=num_classes)\n",
    "        )\n",
    "    elif MLP_used == 1:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=num_classes),\n",
    "        )\n",
    "if backbone == \"efficientnet_b2\":\n",
    "    if MLP_used == 3:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=512, out_features=num_classes)\n",
    "        )\n",
    "    elif MLP_used == 2:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=640),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=640, out_features=num_classes)\n",
    "        )\n",
    "    elif MLP_used == 1:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=in_feat, out_features=num_classes),\n",
    "        )\n",
    "    else:\n",
    "        import sys\n",
    "        sys.exit(\"INVALID number of layers in MLP,, NOT IMPLEMENTED\")\n",
    "    \n",
    "\n",
    "\n",
    "#model.head.fc=nn.Linear(in_features=3072, out_features=num_classes)\n",
    "#model.head=nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a61e529",
   "metadata": {},
   "source": [
    "### Training only classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e1c3ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a2da5f19604bddb726e1e7e14c6912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 0.1185 - acc: 0.3289 - val_loss : 0.1055 - val_acc: 0.4489\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1610efd5735c42c8892c13e81fe69764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 - loss : 0.1123 - acc: 0.3823 - val_loss : 0.1029 - val_acc: 0.4543\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ea24a87d3744c5bce2e1984f5a9a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 - loss : 0.1104 - acc: 0.4020 - val_loss : 0.1032 - val_acc: 0.4595\n",
      "\n",
      "Best acc:0.45951512455940247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss : 0.1032 - val_acc: 0.4595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=False)\n",
    "set_parameter_requires_grad(model.classifier, requires_grad=True)\n",
    "\n",
    "robust = True\n",
    "if backbone == \"vgg19\":\n",
    "    robust = False\n",
    "    \n",
    "train_lossi = []\n",
    "val_lossi = []\n",
    "\n",
    "\n",
    "train(model,3,0.001,robust=robust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebdc2fd2",
   "metadata": {},
   "source": [
    "### Training the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35768527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483e2e77811a481fb969cca488be9bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 0.0996 - acc: 0.4707 - val_loss : 0.0867 - val_acc: 0.5749\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2000df7dae5b487691a31c4e4cf3e3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 - loss : 0.0885 - acc: 0.5532 - val_loss : 0.0851 - val_acc: 0.5766\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4f5e245ae94aeab0c2c770d4fced3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 - loss : 0.0820 - acc: 0.6078 - val_loss : 0.0856 - val_acc: 0.5837\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec53c947cd540bd97dde8fe04e93d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 - loss : 0.0756 - acc: 0.6605 - val_loss : 0.0869 - val_acc: 0.5784\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834812f56f164adfb214f69c483e0dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 - loss : 0.0691 - acc: 0.7133 - val_loss : 0.0886 - val_acc: 0.5700\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afe65e53a944017b61c975895a13509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 - loss : 0.0627 - acc: 0.7715 - val_loss : 0.0916 - val_acc: 0.5722\n",
      "\n",
      "Best acc:0.5837426781654358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss : 0.0856 - val_acc: 0.5837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=True)\n",
    "train(model,6,1e-4,robust=robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eb1cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "PATH = f'./{dataset_used}_{backbone}_mlp{MLP_used}.pt'\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8a5beb7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a68a3306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kaggle_highresAffecnet_efficientnet_b2_mlp1.pt\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return device\n",
    "device = get_device()\n",
    "PATH = f'./{dataset_used}_{backbone}_mlp{MLP_used}.pt'\n",
    "print(PATH)\n",
    "model = torch.load(PATH,map_location=torch.device(device))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d585ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neutral': 0, 'Happiness': 1, 'Sadness': 2, 'Surprise': 3, 'Fear': 4, 'Disgust': 5, 'Anger': 6, 'Contempt': 7}\n",
      "{0: 'Neutral', 1: 'Happiness', 2: 'Sadness', 3: 'Surprise', 4: 'Fear', 5: 'Disgust', 6: 'Anger', 7: 'Contempt'}\n"
     ]
    }
   ],
   "source": [
    "if dataset_used != \"FER\":\n",
    "    class_to_idx = trainset.class_to_idx\n",
    "    print(class_to_idx)\n",
    "    idx_to_class = trainset.idx_to_class\n",
    "    print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c31bf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6311, 8) (6311,)\n"
     ]
    }
   ],
   "source": [
    "y_val,y_scores_val=[],[]\n",
    "model.eval()\n",
    "\n",
    "for image, label in valloader:\n",
    "#     image.unsqueeze_(0)\n",
    "    image = image.to(device)\n",
    "    scores = model(image)\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        score = scores[i].data.cpu().numpy()\n",
    "        y_scores_val.append(score)\n",
    "        y_val.append(label[i])\n",
    "\n",
    "y_scores_val=np.array(y_scores_val)\n",
    "y_val=np.array(y_val)\n",
    "print(y_scores_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63cbcba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.37426715259071\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.argmax(y_scores_val,axis=1)\n",
    "acc=100.0*(y_val==y_pred).sum()/len(y_val)\n",
    "print(acc)\n",
    "\n",
    "# y_train=np.array(trainset.label)\n",
    "\n",
    "# for i in range(y_scores_val.shape[1]):\n",
    "#     _val_acc=(y_pred[y_val==i]==i).sum()/(y_val==i).sum()\n",
    "#     print('%s %d/%d acc: %f' %(idx_to_class[i],(y_train==i).sum(),(y_val==i).sum(),100*_val_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2ee074f",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c88e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
      "(6311,) (6311,) 0.5837426715259072\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAIUCAYAAAAaBSb8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAB3W0lEQVR4nO3dd3gU1dvG8e+ThE5IgFCVIr1Jl6KIoNgoKjZsr6IIigU7VhQBe/mJ2AugggXEioqgghRBekcBAUE6obeU3fP+sUsIGIqw2UmY+3NdXGzOzs4+Z2fLPWfO7phzDhERERE/iPG6ABEREZFoUfARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd+I87qA3C5v4USXv1gZr8uIqkpJBb0uIer8+KsPQR92Ok+s//YFfbiZSQ8GvS4h6vy2nVevWsmWzZssq+sUfI5T/mJlOO2BgV6XEVXDbzrN6xKibk9qwOsSoi4l3X8fDiWL5PO6hKgLBH32iQgk70z1uoSoS0nz1+v5igvPPOR1/tu9EREREd9S8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER34jzugA5vBiDVy6rS/KuVJ784Q8K54vjoXOrUjI+Hxt2pPDs6MXsTA0AcEWDspxXsxRB53h74nJmrtrmcfXHbm9KGpfdMYCU1HQCgSDtWtfj/i4X8u0vs3l54CiW/L2e7969h3o1yntdakRt37mHh18cxpLlazEznnmgE6MnzOOXyQvIkyeO8mWK89yDV1GkcAGvS42YD0aMZ8SoqRhQ9ZQyPHX/lYybspDXPxrDspUb+HTAndSpVs7rMiOmR7+hjJm0gKSi8Uz4+GEAnn/3ez76ZjLFEwsD8Gj39px7em0vy4yY1eu3cGffIWxM3oHFGP93UXO6dmrFN7/M4sX3R7FkxXp+eO9e6tc8sV7LWT2vBwz+kXFTFpInTyzlyhSn3/2dcvVrufcrw5kwdRHFEgsz/I17Adi2YzcPPTuUNRu2ULZkUZ576FqKxBckLT1A31c/54+la0gPBGh/TiNuurK1J3XnyBEfM3Nm9lKmv+83s97HuK5EM7vtGG+7wsySjuW2kXLRqWVYtXVPxt9XNCjLnNXb6PbJbOas3sYVDU8CoFzRArSskkT3T2fz+MhF3HZmJWLMq6qPX768cQzrfzs/fdCT0YMfYNyURcyYv4IalUrz7tM30qxeJa9LzBZ9X/uKlqdVZ/QHD/Htu/dRpUIpzmhUje8HPsB3793PKeVK8NbHP3tdZsSs37SNoV9NZNhrd/H1u/cTDAb5ftxsqlQsTf/Hr6fxqad4XWLEXdWuKZ/+r/u/2m+9qhXjPnqQcR89eMKEHoC42Bh633kJEz55hO/fuYdBX0zkz+XrqFGpDAOfvolm9St7XWLEHep53bxhVb569z6+fPs+Kpxcgnc//cXrUo9LhzaNeK1PlwPaBg0fR5N6Vfj63Z40qVeFQcPHAfDTxLmkpqUz7I17GNq/ByN++J016zd7UHUODT5ACnBphEJHIpBl8DGz2AisP9sUL5SX0yoU5cdF6zPamp1SjJ/+3AjAT39upNkpxULtFYsyfukm0oOO9TtSWLNtL9VKFvak7kgwMwoVzAdAenqAtEAQM6hasTRVypfyuLrssWPXXqbNXcaVbZsCkDdPHEUKF+DM06oTFxt6qtavWYF1G7d6WGXkBQJB9qakkR4IsDcljZLFilC5fClOKVfS69KyxekNqlC0SEGvy4iaUkkJ1K0eGrErXCg/VSuUYt3GrVSrWJoqFU7M1zJk/bw+o/H+13K9GuVZvzH3jsoDNKpTiYT4A0esfp2ygPZtGgHQvk0jxk1ZAIBh7NkbejxSUtPIExdLoYL5o14z5NxDXenAO8A9wKOZrzCzEsBbwL5x0budc5PCI0I7nXMvhpebD7QHngUqm9lsYAzwHfAEsBaoD9Qys6+AckB+oL9z7p1s7NtR63ZGRQZN/psCeffns8QCediyOw2ALbvTSCyQB4DihfLx5/odGcsl70qleKG80S04wgKBIBd0eZEVqzfRuWMLGtau6HVJ2WrV2mSKJRTiwec/ZdFfa6hT7WR63X4JBQvky1hm+A9Tade6vndFRlippAQ6X3EWba57ivz58nB6w2qc0bi612V54v3hExj2/TTq1SxHnx4dSTwBw9HKtcnMX/LPCf9aPprn9Rc/TuPCs+p5VGH2Sd66kxLFigBQolgRNm/dBcA5LU5l3O8LOO+6p9ibksp9XTuQEO/NczynjvgAvA5ca2YJB7X3B/7nnDsNuAx47wjreQj4yzlX3zn3QLitCfCoc65W+O+bnHONgMZADzMrfrgVmlk3M5tuZtNTd275L306aqdVSGTbnjSWbtp1VMtbFoe1XIRrirbY2BjGDO7J9C96M2vRSv5YttbrkrJVIBBkwZLVXHPR6Xz7zn0UzJ+Ptz/ZPxT+xpCfiIuN4eI2DT2sMrK27djNL78tYPSHDzP2k17s2ZvKtz/N8LqsqOt8aQumjXicsR/1pFTxBB5/9UuvS4q4XbtTuPmRgfS561LiC3mzpx8tR3pev/3xz8TFxtD+nBPntXwkCxavIjYmhh8/epSRAx9iyJfj+Wdtsie15Njg45zbDnwI9DjoqjbAa+ERnG+AImYW/x9XP9U5tzzT3z3MbA4whdDIT9Uj1PaOc66xc65x3sJF/+NdH51apYvQtGJRBl7bgAfPrUrdk4pw/zlV2LonjaIFQ6M8RQvmYeue0OjPpp0pJBXeP8JTvFBeNu9KzZbaoi0hviCnN6jCuCmLvC4lW5UukUDpEgnUr1kBgAta1mXBktVAaO/wlykLefnRa7GsUm4uNWXWEk4uXYxiiYXJExdLmxZ1mLXwb6/LirqSxYsQGxtDTEwM/3dxc2YtXOl1SRGVlh6gyyMDufS8xrRrdeKNchzscM/rr0ZP59ffF/LcQ9ecUK/lfYonFmbj5u0AbNy8nWKJhQD4YdxsmjeqTp64WIolFqZerYosXPqPJzXm2OAT9grQBSiUqS0GaB4ewanvnDvJObeD0OGxzP053C5FxjCKmbUiFKaaO+fqAbOOcNuo+OD3ldzw0UxuGjqL58YsYe7q7bz481J+X7GFNtVLANCmegmmLA9NDvt9xRZaVkkiLsYoFZ+PkxLzs3jDTi+7cFySt+xk247dAOxJSWXC9MVUPoHnA0BoWLhMyUSWrdwAwG8zl1ClQil+nfoHb386lrf73USB/Ln78OXBypQoypw/VrJnbyrOOabMWkrl8ifm3J7DWbdp/1yP73+dS41KZTysJrKcc9zz9CdUrViKW6/25ls80Xao5/WEaX/w/rCxvPbkjSfca3mflk1rMTI8ujXypxmc1Sw0Ub9MiUSmzVmKc449e1OZ98dKKp7szWvdnMt5B0TMbKdzrnD48vPAVcBA51xvM/sYmOWceyF8fX3n3Gwzuw5o75y7yswaAtOAysAOYKZzrkJ4+VbA/c659uG/LwZuds51MLMawGzgAufcODNbATR2zm06VK1Fytd0pz0wMBsehf1OLVuES+uV5ckf/iA+XxwPnVeNEoXzsnFnKs+MXszOlHQAOjU8iXNrlCTgHO9MWsGMlVuzpZ7hN52WLevNbOHSNdz91FCCwSDBoKPD2fW558YL+OHXuTz2ygg2b91JkcIFqF31JD5++d/fkIm0PeGfDMhuC5eu5pEXh5GWHqBcmWI81/MqOnZ/hdS0dIoWCeX/+rUq0Peey7O9lpT0YLbfB8BrH/7IqHFziI2NoWaVk+hzzxWMn7qIp9/4ms3bdlKkUAGqVy7Lu890zfZaShbJd+SFjlO3XoOZNHMpm7fupESxeHp2bctvM5cwf8lqDKNcmWK8+FAnSicdfJQ/ewSC2fsZ8Pucv7i4+6vUrFyGmJjQvunDt7QjNS2dR18eQXL4tVyn6sl8+kr2v5YBkndm/2h4Vs/ri7q9SFpqOgnh+Vv1albgibsuy/ZaAFLSIv96fvi5j5kxbxlbt++iWGJhbr32XFo1r82Dzw5l3catlC6RyPMPX0dCfEF270mh9/+Gs2zVepyDi85tzA2XnRXxmva54sIzmT9nZpZDarkh+JQClgPPh4NPEqH5PzUJTc4e75y71cwKAF8DJQmFnhbAhc65FeGwVBf4gdDk5szBJx/wFXAS8CdQAuidk4JPThON4JPTRCv45CTRCj45STSCT06T3cEnJ4pG8MlpsiP45GSHCz458ltd+0JP+PJ6oGCmvzcBnbK4zR7gvEOs75qDmsZlui4FuPAQt6v4H8oWERGRHC6nz/ERERERiRgFHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxjTivC8jtKiUVZNhNp3ldRlSd1OJur0uIui3TXvO6hKhLSw96XULUxcX6cV/Qf9u5bNECXpcQdauSd3tdQlTZYa7z46tcREREfErBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHwjzusC5Mj2pqRx2R0DSE1NJxAI0rZ1Pe7vcmHG9W99/Av93viGuSP7USyxsIeVHr8ihQvw6mPXULNyGZyDO/sOZdq85QDccd059L2rI5XbPMjmbbsAuKfzeVx3UXMCwSAPvfg5v0xZ5GX5EfPPui107/0hG5K3E2PGDR3P4NarW3tdVsTd1W8oY35bQFLReMYPfTij/b3hv/L+5xOIi42hzem1eeKOiz2sMvvsTUmjXbdXSElLJ5Ae4KJzGvDwLe28LivievQbyphJoe084ePQdv7651m88N4PLF6xntED76N+zfIeV5l9/LKdh3w1kRE//A4OLr2wCf/X8UxGj5/Lm0PGsGzVBj7ufwe1q5XzuszsCz5mttM5VzjT352Bxs65OyJ8P98D1zjntkZyvTlJvrxxDOt/O4UK5iMtPUDH7v1p3bQmjepUZM36LUyY/icnlSrqdZkR8ex9l/Pz5IV0fuh98sTFUiB/XgBOKpVIqyY1WLV2c8ay1U8pzaXnNqR5p6coXSKBr16/g8aX9SEYdF6VHzFxcTH0u/tS6tUox45de2l9/XO0alqDGpXKeF1aRF3VrildrmjJHX2GZLRNnLGYH8bPY9xHD5Ivbx42bt7hYYXZK1/eOL5+sweFw6/tC29+mTan1+K0U0/xurSIuqpdU7pcfuB2rlmpDIOf7cJ9z37mYWXR4YftvGTFOkb88Dsf97+TPHli6f7o+7RsUoMqFUvxcq//o++rX3hdYoZcf6jLOdf2RA49AGZGoYL5AEhPD5AeCGIWuq73gK94tPtFGX/nZvGF8nN6g8p89PVkANLSA2zfuQeAp+65jN4DvsK5/aGm7Vl1+WLMTFLT0lm5JpllqzbRqHZFL0qPuNJJCdSrEdozii+Un2oVS7N241Zvi8oGzRtUIbFIwQPaBn8xkR7/dy758uYBoESxeC9Kiwozo3D4tZ2WHiAtPYCdCC/mg5zeoApFD9rO1U4pTZUKpTyqKLr8sJ2Xr9xA3RrlKZA/L3GxsTQ+tRI//7aASuVLcUq5kl6XdwBPgo+ZdTCz381slpn9ZGalwu29zewjM/vFzJaYWddweyszG29mX5rZQjN7y8xiwtetMLMkM6toZovM7F0zW2Bmo82sQHiZymY2ysxmmNkEM6sRbr/CzOab2RwzGx9uq21mU81stpnNNbOqXjxGBwsEgpzX+XnqdXiMMxtXo2HtioyeOJ/SSQnUqnqS1+VFRIWTirNp605ef+I6fh3yIP0fvYaC+fNyYctTWbtxK/OXrD5g+TIlEli9fkvG32s2bKFMiYRol53tVq5JZu6f/5wwoe5I/lq1kSlz/uKCLi9xcff+zFr4t9clZatAIMiZ1zxDtfMeolXTGjSuU9HrkiQbnOjbuUrFUsycv5yt23exZ28qE6b9wfocurOWncGnQDg8zDaz2UCfTNdNBJo55xoAnwI9M11XF2gHNAceN7Oy4fYmwH3AqUBl4NIs7rMq8LpzrjawFbgs3P4OcKdzrhFwP/BGuP1x4HznXD3gonDbrUB/51x9oDHwz8F3YmbdzGy6mU1P3rTpaB6L4xYbG8PowT2Z9kVvZi9aycKla3j1g9Hcf/OFR75xLhEXG0u96uUY+PkEzrruOXbvTeGhbm2598bzeeat7/61fFZ7TC73H+U6wM7dKVz/4Hs8c+9lFClcwOtyoiIQCLJtx25+eO9enrjjEro+NuiAkb4TTWxsDBM+fpgF3/Vj5oK/Wbh0jdclSTY40bdzpfKluPGKVnR7+F26P/Y+1SuVITY2Zx5Uys6q9jjn6u/7Ryhk7HMy8KOZzQMeAGpnuu5r59we59wmYCyhwAMw1Tm3zDkXAD4BWmRxn8udc7PDl2cAFc2sMHA6MDwcwN4G9k2UmAQMDo8sxYbbJgOPmNmDQAXn3J6D78Q5945zrrFzrnHxpKSjfkAiISG+IM0bVGH0xHmsWruZ8zo/T7PLn2Ttxm1ccNOLbEjeHtV6ImnNhi2s2bCVGQtCe/jf/DybujXKUaFscSZ8/DBzvn6SsiUT+XXIg5QsHs+aDVsPmNtUtmRR1m3a5lX5EZeWHuCGB9/ligsa0+Hs+l6XEzVlSiTQrlU9zIyGtStgMUby1p1el5XtEuIL0qJRVX6evNDrUiQbncjb+dILmjDs9bsZ/GJ3isQXpHzZ6H4+Hi2v4tgA4DXn3KnALUD+TNcdvGvnjtCeWUqmywFCk7djgK2ZQ5hzriaAc+5W4DGgHDDbzIo75z4mNPqzh1A4O/u/dy+ykrfsZNuO3QDsSUll4vTF1Kl6MnNG9mPK508w5fMnKFMigVED76dk8SIeV3vsNiTvYPX6LVSpEDoe3PK06sz9YxXVzn+Yehc/Qb2Ln2DNhq2cdd1zbEjewQ/j53LpuQ3JmyeO8mWLU7l8CWYsWOFtJyLEOcedfYdSrWJpbr/2HK/LiaoLW9ZlwvTFAPy1cgNpaQGK5/JvKx7Kpi079r+296YybuqfVK3oj3kvfuKX7bxvB2Xthi38PGk+bVvV97agQ/Dq6+wJwL4JGzccdN3FZvYMUAhoBTwEVAOamNkpwN9AJ0KHr47IObfdzJab2RXOueEWOj5S1zk3x8wqO+d+B343sw5AOTNLAJY55141s0qEDr39cnzdPT7rk7dzz1NDCQSDuKCj/dn1aXNG7SPfMBfq+eJw3unTmbx5YlmxehO3Z/oWyMH+WLaOr36axZRhj5IeCPLA88NOiG90AUyZs4zPvp9KrSplOfOaZwDodftFnHeCbfdbHh/MpJlL2bx1J/Uu6kXPm9tyTYdm3PXUx7S89hnyxMUyoNd1J9xE0H3WbdrObb0/IhAMEgw6OrZpyAVnnup1WRHXrdf+7Vy3Qy96dm1L0SIFefilz0neupNr7n2b2tVOYnj/27wuNVv4ZTvf2/dDtu3YTVxsLI/cfglF4gvy86T5PPPm12zZtpPbHx9EjUpleevpmz2t07Lr2Pnhvs5uZhcD/yMUfqYApznnWplZb6AsoTk85YHnnXPvmlkrQofKNhKa4zMeuM05FzSzFYTm4hQGRjrn6oTv736gsHOudzgwvUnoEFce4FPnXB8z+4LQvCADfgbuJhS0rgPSgHWEviq//zvUB6nfsJH7ecLvx/lo5S4nt7jb6xKibsu017wuIerS0oNelxB1eeJy5pyE7JQe8N92jsuhc0+y06rk3V6XEFWXnteCeXNmZrnHlG0jPplDT/jvwcDg8OWvga8PcdPFzrluWbTvds51yuJ+KoYvbgLqZGp/MdPl5cAFWdw2qwnSz4T/iYiIyAnGf7FXREREfCtHnbLCOdf7EO3jgHHRrEVEREROPBrxEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd+I87qA3C4t3fFP8h6vy4iqDZNf9bqEqDvjmbFelxB1o+890+sSom53asDrEqIuxryuIPr2pKZ6XULUlYjP53UJURUXe+hxHY34iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG/EeV2AZK3fq58zafofFE0ozMcD7gZgwKDvmTjtD+LiYjm5dDEe63E58YULALBkxVqee+NLdu1OISbGGPji7eTLm8fDHhyfu/oNZcxvC0gqGs/4oQ9ntL83/Ffe/3wCcbExtDm9Nk/ccbGHVUZGjMH7nRuzcWcKPYfPo2vLU2hRNQnnHFt2p/HUyEVs2pkKQOUSheh5YXUK5Y0j6Bw3D55BaiDocQ+O3d6UNC67YwCpqekEAkHatq7H/V0uzLj+rY9/od8b3zB3ZD+KJRb2sNLICgSCdOj2MqVLJDDw2a4ADB4xng+/nEhsbAxnN6vFw90v8rjKyAoEgrTv9jKlkhIY/FxXXnzve0ZPnE9MjFE8sTAvPXINpZMSvC4zIpat2sA9/YZk/L1qbTI9bjif9Zu2MXbKQvLExVG+bHGeeaATRcLv4bnd6vVb6NF3CBs27yDGjOsubk7XK1txS6/B/LVyAwDbdu4hoXABfvqgp6e15ojgY2aPAtcAASAI3OKc+/0oblcRGOmcq5O9FUZfu3MacXm75vR5ZXhGW5P6Veh+/fnExcby2gc/8MGIcdxxw4WkBwL0fnkYve+5kqqnlGHb9l3ExcZ6WP3xu6pdU7pc0ZI7+ux/85g4YzE/jJ/HuI8eJF/ePGzcvMPDCiPnisblWJG8m0L5Qtts6JSVvDt+OQCXNz6JG8+oyAs/LibWjMcvqkXfbxeydMMuihSIIz2Ye0MPQL68cQzrfzuFCuYjLT1Ax+79ad20Jo3qVGTN+i1MmP4nJ5Uq6nWZETfo8/FUqVCKnbv3AvDbzCWMmTSfHwb2JF/eODZtOTGe25kNDPd5x65Qn2+5+mzuv7ltxnX9B//IM/df6WWJEVOpXEm+fvteIBT4Wl7Vl3Nb1GH5qo3cd3Nb4mJjeeHdkbz9yc880LW9x9VGRlxsDE/ceQl1q5dj5669nN/lRVqeVoO3+3bOWKb3gC8pUsj7oOf5oS4zaw60Bxo65+oCbYBV3lblvQa1T6FI4YIHtDVtUC0j0NSpVp4Nm7YBMHXWEqpULE3VU8oAkFCkELGxnm/a49K8QRUSixzY/8FfTKTH/52bMZJVoli8F6VFVIn4fJxepTjfzlmT0bY7NZBxuUCeWFz4cpNKRflrw06WbtgFwPY96QQduZqZUahgPgDS0wOkB4KYha7rPeArHu1+UcbfJ4q1G7byy5SFXNW+WUbb0K8n0f2ac8iXN7QvmlQ09z+3M1u7YSs/T17IVe329zm+UP6My7v3pmIn2oYOmzxrCeXKFuekUsVo0bh6xnt4/ZoVWLdxm8fVRU6ppATqVi8HQOFC+alaoRTrNm7NuN45x7e/zOaScxt6VOF+OWHEpwywyTmXAuCc2wRgZo8DHYACwG+ERoGcmTUCBgK7gYn7VmJmnYGLgIJAZeBL51zP8HXnAU8C+YC/gBudczvN7NnwbdKB0c65+83sCuAJQqNP25xzLbO5/8fk25+n06ZFXQBWrtmEGdz1xEC2bN/FuWfW5f8uPcvjCiPvr1UbmTLnL555eyT58sbR+85LaFCrgtdlHZe72lThjbFLKZj3wJdit5ancMGppdmVks6dQ2cDUK5YQRzwcqd6JBbMw08LN/Dx7yujX3SEBQJBLuzyIitWb+KGji1oWLsioyfOp3RSArWqnuR1eRHX57UvefjWDuzcnZLRtuyfjUydu4wX3vuefHnz8Gj3i6hXs7yHVUZW7wFf8kj3DuzK1GeA59/9jhGjphNfOD+f9b/do+qy13djZ9O+df1/tY8YNZULW/27/USwam0y85b8Q8PaFTPapsz5i6Si8VQqV9K7wsJywrDAaKCcmS02szfMbN8n9mvOudPCh7EKEBoVAhgE9HDONc9iXfWBTsCpQCczK2dmScBjQBvnXENgOnCvmRUDOgK1wyNN/cLreBw43zlXj1AoynEGDRtLXEwMF5xVHwh9cMxZ+DdP3teJd569hV+nLGDanKXeFpkNAoEg23bs5of37uWJOy6h62ODcC73DnmcXqU4W3an8ee6nf+67p3xy7n09cmMXrCeyxqHPvxjzah7cgJPfrOQ7h/N5KzqSTSqkPsPA8XGxjB6cE+mfdGb2YtWsnDpGl79YDT333zhkW+cy/z82wKKJ8ZzanjPeJ9AIMj2HXv46s27eaR7B27v/UGufm5n9lN4rl7dg/oM0LNrO34f8QSXnNuIwV9M8KC67JWals4vkxdwwVn1Dmh/c+hPxMbGctE53o9+RNqu3Sl0eXQgfXpcesCo3ldjZtIxB4z2QA4IPs65nUAjoBuwEfgsPHrT2sx+N7N5wNlAbTNLABKdc7+Gb/7RQav72Tm3zTm3F1gIVACaAbWASWY2G7gh3L4d2Au8Z2aXEhpBApgEDDazrkCWE2XMrJuZTTez6Vs2bzr+B+E/+O6XGUyavogn7+uUMTRcsngCDeqcQmKRQuTPl5fTG1Xnz7/WHGFNuU+ZEgm0a1UPM6Nh7QpYjJG89d+hIbeoe1ICLaoU5/PuzXjy4lo0qlCUxzvUPGCZ0QvW06p6CQA27Ehh9sqtbNuTRkp6kMl/JVO99Ikz4TchviDNG1Rh9MR5rFq7mfM6P0+zy59k7cZtXHDTi2xI3u51icdt+vzl/PTbfM7o1Ic7+3zIbzOXcHe/IZQukcj5LetiZtSvWYGYGGPztl1elxsR0+ctZ8yk+Zx+ZR/ueDLU57v6DjlgmUvaNOSHX+d6VGH2GT/1D2pXPfmAQ5dfjp7GuCmLePHha064w3tp6QG6PDqQS89rTLtW+8NeenqA73+dk2OCXk441IVzLgCMA8aFg84tQF2gsXNulZn1BvIDBhxuNyjzOGqAUP8MGOOcu/rghc2sCXAOcBVwB3C2c+5WM2sKtANmm1l951zyQfW+A7wDULtuw6jtlk2e+ScfjRjPm093JX++vBntTRtW46Mvx7M3JZW4uFhmzl/O1Re3iFZZUXNhy7pMmL6YMxpW5a+VG0hLC1A8F3/T561fl/HWr8sAaFA+kaublqPPt4s4uWgB/tmyB4Azqybxd3Iok09dvplrm5UnX1wM6QFH/XKJfDbtH8/qj4TkLTuJi4shIb4ge1JSmTh9Mbddew5zRvbLWKbZ5U/y/Xv3nRDf6nqwW3se7BYavJ48aynvfjaWVx67jiFfT2LyzCU0b1CFZatCz+1iCYU8rjYyHrqlPQ/dsr/Pb386lv69rmP5qo2cUi4U6sdMmk/l8t4fAom078bOpl2mw1zjp/7Bu5+OZcjLt1Egf95D3zAXcs5x7zOfULVCKW69qvUB142fvpgqFUpRtmSiN8UdxPPgY2bVgaBzbkm4qT7wJ6Hgs8nMCgOXA58757aa2TYza+GcmwhcexR3MQV43cyqOOeWmllB4GRgDVDQOfe9mU0BlobrqRz+RtnvZtYBKAckH2rl2aXXi58wc/5ytm7fRYebnqHr1W348PNxpKYF6PHEQADqVCvHg7d1pEjhAlx9cQtuvO91zIzmjapzRuMa0S45om55fDCTZi5l89ad1LuoFz1vbss1HZpx11Mf0/LaZ8gTF8uAXtedcHtMAN1bVaJ88YIEHazbtpcXRv0JwI696Xw6dRXvd26MwzH5r81M/ivqT82IWp+8nXueGkogGMQFHe3Prk+bM2p7XVbUXdm2KT2f+5TzOj9HnrhYXnrkxBsNONizb4/kr1UbiDHjpNJFeea+K7wuKaL27E3ltxmL6XP3ZRltfV/7ktS0dG588B0A6tUsT5+7L/eqxIiaOncZn4+aRs3KZWhzw/MAPHxLO845vTZf/zSTS9rkjNEeAPP6OHJ4svIAIJHQJOOlhA573U1oJGYFoW95/e2c633Q5OYfgcudc3XCh8caO+fuCK93JPCic26cmZ0NPEdocjOE5vxMA75m/0jSi865D8zsC6BquO1n4G53mAepdt2G7uORvx7q6hNSpZInxp7of9HqBX9tY4DR957pdQlRlx44MebV/BcxJ3a+ytKeTN+c9IsiBXLv77odi9YtmjJr5vQsn92ej/g452YAp2dx1WPhf1ktn3mmWO9w+2BgcKbl2me6/AtwWhb30SSL9V96VIWLiIhIruP55GYRERGRaFHwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER31DwEREREd9Q8BERERHfUPARERER34jzuoDcLi7WKJ2Y3+syomrLrlSvS4i6X+5v6XUJUXdqz++8LiHqRj9yjtclRF3ZogW8LiHq4mL9t88fE2NelxBdh+mu/7a+iIiI+JaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+Eac1wXI0QsEgnTo9jKlSyQw8NmuAAweMZ4Pv5xIbGwMZzerxcPdL/K4yshYtmoD9/QbkvH3qrXJ9LjhfNZv2sbYKQvJExdH+bLFeeaBThQpXMDDSiNn9fot3Nl3CBuTd2Axxv9d1JyunVrxzS+zePH9USxZsZ4f3ruX+jXLe13qcYsx+OLes1i/bQ+3vDeVGmWL8OQVdSmYN47VW3Zz30cz2ZWSTmLBPLza+TROLZ/Il1NX0eeLeV6Xfkx6/28446cuolhiYT5/814Atu3YzYPPDGXNhi2ULVmU5x++liLxBZkyczGvDh5FWlqAPHliufumtjSpX8XjHhyfu/oNZcxvC0gqGs/4oQ8DsGDJah54/jN27U6hXJlivPnk9cQXOjFey3tT0rj09ldJTUsnPT1Iu9b1eODmtmzZvotbew3mn3WbObl0Md7ueyOJRQp6XW7E5JbtnCNGfMzsUTNbYGZzzWy2mTXNpvv53swSs2Pd0TDo8/FUqVAq4+/fZi5hzKT5/DCwJ2M+eIiuV7X2sLrIqlSuJF+/fS9fv30vX7xxNwXy5eXcFnU4o1E1Rr53P9++ex8VT07i7U9+9rrUiImLjaH3nZcw4ZNH+P6dexj0xUT+XL6OGpXKMPDpm2hWv7LXJUbMDS0r8df6HRl/P9WpHi+OXESHF8YxZu5abj471NeU9CD9f/iD575Z4FWpEdGhTSNe79vlgLZBw8bRpH4VvnmvJ03qV2HQ8HEAJCYU4pUnOjP8zXvoc++VPPbSZx5UHFlXtWvKp//rfkDbvc98wmPdO/Dr0Idpe1ZdXh/yi0fVRV6+vHEMf/UOfvrgQcZ80JNxv//BjPkreO2jn2jRuBqTPutFi8bVeG3IT16XGlG5ZTt7HnzMrDnQHmjonKsLtAFWHeVtj2rEykJinHNtnXNbj7lYD63dsJVfpizkqvbNMtqGfj2J7tecQ768oYchqWi8V+Vlq8mzllCubHFOKlWMFo2rExcbC0D9mhVYt3Gbx9VFTqmkBOpWLwdA4UL5qVqhFOs2bqVaxdIHBN7crlRCflrVKsXwKSsz2k4pWZhpfyUDMGnxRs6vWxaAPakBZizfTEpa0JNaI6XRqZVIiD9wL3fclAV0aNMICAWjsZND4a5G5ZMoWbwIAJUrlCI1NZ3UtPToFhxhzRtU+dfIxtK/19O8QWgk66wmNfhu3GwPKsseZkahgvkASEsPkJYewAx+nDCfKy9sAsCVFzZh1PjcOYJ5KLllO3sefIAywCbnXAqAc26Tc26Nma0wsyQAM2tsZuPCl3ub2TtmNhr40Mw6m9nXZjbKzP40syfCy1U0s0Vm9gYwEyi3b51mVsjMvjOzOWY238w6hW/TyMx+NbMZZvajmZXx4PHIUp/XvuThWztgZhlty/7ZyNS5y7j41v9xZY/XmLNo5WHWkHt9N3Y27VvX/1f7iFFTadmkRvQLioKVa5OZv+QfGtau6HUpEfdoxzo8/+1Cgs5ltC1eu4Nz6pQG4MJ6ZSmdeGIc8jic5K07KVEsFHBKFCvC5m27/rXMT5PmUb1yWfLmOfFmJdSoVIZRE0If/N/+MovVG7Z6W1CEBQJB2tzwPHXbP0rL06rTsHZFNm3ZQamkBCC0o5O8dccR1pL75cTtnBOCz2hCoWSxmb1hZmcdxW0aARc7564J/90EuBaoD1xhZo3D7dWBD51zDZxzf2e6/QXAGudcPedcHWCUmeUBBgCXO+caAQOBp467dxHw828LKJ4Yz6nh0YB9AoEg23fs4as37+aR7h24vfcHuEwfJieC1LR0fpm8gAvOqndA+5tDfyI2NpaLzmnoUWXZZ9fuFG5+ZCB97rqU+EL5vS4nolrVKkXyjhQW/HPgSN0jn87m2hYV+eLelhTKH0daIHeP8ETCX3+v49WBP/DYnZd6XUq2eOXRaxk0YgLndn6enbtTyBsX63VJERUbG8NPH/RkxpdPMnvh3/yxbI3XJXkiJ25nz3cjnHM7zawRcCbQGvjMzB46ws2+cc7tyfT3GOdcMoCZfQG0AL4C/nbOTcni9vOAF83sOWCkc26CmdUB6gBjwqMqscDarO7czLoB3QBOLpf9E02nz1/OT7/NZ+zvC0lJTWfnrr3c3W8IpUskcn7LupgZ9WtWICbG2LxtF8UTC2d7TdEyfuof1K568gGH8b4cPY1xUxYx+IVbDhgBOxGkpQfo8shALj2vMe1a1TvyDXKZRqcU45w6pTmrVinyxcVQOH8cL1zbkAeGzuSmt0Iv1YolCtGq5olzaO9QiicWZuPm7ZQoVoSNm7dTLKFQxnXrN23l3r4f0fe+TpQrU9zDKrNP1YqlGNb/dgD+WrmBMZNy9zyuQ0mIL0jzhlUYO+UPkorGs37TNkolJbB+0zaKJ56Y0xMyy4nbOSeM+OCcCzjnxjnnngDuAC4D0tlf38G7vQePCR88zOEOsdy++1tMaNRoHvCMmT0OGLDAOVc//O9U59x5h7j9O865xs65xsWKJx1NF4/Lg93aM+Xz3kz67HEGPH49pzesyiuPXcd5LeoweeYSIPQtqLS0wAFvnieC78bOpl2mw1zjp/7Bu5+O5c2+N1Igf17vCssGzjnuefoTqlYsxa1XnzgT1TN76btFtHxyDGf3/Yl7PpzBlCWbeGDoTIoVDm1LM7jt3Gp88tsKbwuNgrOa1eLbn2YA8O1PM2jVrDYAO3bu4c4nBnNn5wuofwIe6txn4+bQYZ5gMMj/Bv3IDR3P8LiiyEnespNtO3YDsCcllQnTFlOlQknOa1GHYT9MBWDYD1M5/8w6XpYZFTlxO3s+4mNm1YGgc25JuKk+8DdQgFA4+YFQEDqcc82sGLAHuAS46Qj3WRbY7JwbYmY7gc7As0AJM2vunJscPvRVzTnnfTw9hCvbNqXnc59yXufnyBMXy0uPXHNCjYDs2ZvKbzMW0+fu/Zu/72tfkpqWzo0PvgNAvZrl6XP35V6VGFFT5y7j81HTqFm5DOfc8DwAD9/SjtS0dB59eQTJW3dy3f1vU6fqyXz6SvcjrC13ad/wJK494xQAxsxby4ip+7/f8EuvNhTOF0eeuBjanFqaG9+azF/rd3pV6jF56LmPmTF3GVu37+L8/3uKW687lxuvaMWDzwzlq9HTKFMikecfuQ6AT7/9jVVrNvHupz/z7qehby2+2e9miuXikdxbHh/MbzOXsnnrTupf1IsHbm7Lrj0pDBoxAYC2repxdaYvbuR265O3cVe/oQSDQYJBR4ezG3DuGXVoVOcUbu01iE9HTuGkUkV5u9+NXpcaUbllO5vXc0LCh7kGAImERnmWEjqMVBN4H1gP/A40ds61MrPewE7n3Ivh23cG2gKFgCrAx865J82sIqHDWHUy3dcKoDGhQPUCEATSgO7OuelmVh94FUggFApfcc69e7j66zVo5Eb/mtXRtBNXSlrA6xKiLqFgHq9LiLpTe37ndQlRN/qRc7wuIerKFj3xJ5IfLBA8seZCHo3YmBNnp/honHVGE2bNmJ5lpz0f8XHOzQBOz+KqCUC1LJbvncWyG5xzdxy03ApCc3Yyt1UMX/wx/O/gdc8GWh65ahEREcmNcsQcHxEREZFo8HzE53g55wYDgz0uQ0RERHIBjfiIiIiIbxxyxMfMBvDvr4lncM71yJaKRERERLLJ4Q51TY9aFSIiIiJRcMjg45z7IPPfZlbIOZflDwKKiIiI5AZHnONjZs3NbCGwKPx3vfCJP0VERERylaOZ3PwKcD6QDOCcm4N+60ZERERyoaP6VpdzbtVBTf776V4RERHJ9Y7md3xWmdnpgDOzvEAPwoe9RERERHKToxnxuRW4HTgJWE3oJKK3Z2NNIiIiItniiCM+zrlNwLVRqEVEREQkWx3Nt7oqmdm3ZrbRzDaY2ddmVikaxYmIiIhE0tEc6voYGAaUAcoCw4FPsrMoERERkexwNMHHnHMfOefSw/+GcJhTWYiIiIjkVIc7V1ex8MWxZvYQ8CmhwNMJ+C4KtYmIiIhE1OEmN88gFHQs/Pctma5zQN/sKkpEREQkOxzuXF2nRLMQERERkex2ND9giJnVAWoB+fe1Oec+zK6iRERERLLDEYOPmT0BtCIUfL4HLgQmAgo+IiIikqsczbe6LgfOAdY5524E6gH5srUqERERkWxwNMFnj3MuCKSbWRFgA6AfMBQREZFc52jm+Ew3s0TgXULf9NoJTM3OokRERESyw9Gcq+u28MW3zGwUUMQ5Nzd7yxIRERGJvMP9gGHDw13nnJuZPSWJiIiIZI/Djfi8dJjrHHB2hGvJlcxC//wksVBer0uIuu170rwuIereubW51yVE3e2f+28we9hNp3ldQtSlB/x31qWEgnm8LiGqDjeB+XA/YNg6G2oRERER8czRfKtLRERE5ISg4CMiIiK+oeAjIiIivnHE4GMh15nZ4+G/y5tZk+wvTURERCSyjmbE5w2gOXB1+O8dwOvZVpGIiIhINjmaX25u6pxraGazAJxzW8zMf99nFhERkVzvaEZ80swsltBv92BmJYBgtlYlIiIikg2OJvi8CnwJlDSzp4CJwNPZWpWIiIhINjiac3UNNbMZwDmAAZc45xZle2UiIiIiEXbE4GNm5YHdwLeZ25xzK7OzMBEREZFIO5rJzd8Rmt9jQH7gFOBPoHY21iUiIiIScUdzqOvUzH+Hz9p+S7ZVJCIiIpJN/vMvNzvnZgL+O52viIiI5HpHM8fn3kx/xgANgY3ZVpGIiIhINjmaOT7xmS6nE5rzMyJ7yhERERHJPocNPuEfLizsnHsgSvWIiIiIZJtDzvExszjnXIDQoS0RERGRXO9wIz5TCYWe2Wb2DTAc2LXvSufcF9lcm4iIiEhEHc0cn2JAMnA2+3/PxwEKPiIiIpKrHC74lAx/o2s++wPPPi5bqxIRERHJBocLPrFAYQ4MPPso+IiIiEiuc7jgs9Y51ydqlYiIiIhks8P9cnNWIz0iIiIiudbhgs85UatCREREJAoOeajLObc5moXIkQUCQdp3e5nSSQkMeq5rRvvbn4zl6Te/YdY3fSmWWNjDCiPnrn5DGfPbApKKxjN+6MMALFiymgee/4xdu1MoV6YYbz55PfGFCnhcaWRt37mHR14cxpLla8GMZx/oRIPaFQF477OxPPf2SH7/8kmKJeTe7Tzgna+ZPnsxCUUK8eqztwGw/O91vDVwJKlp6cTGxtCtczuqVT6JtPQAb70/kqXL1xATY3S57gLq1KrobQf+ozyxxnMX1yFPrBEbY0xalszQaf9wSvGC3N6yEgXyxLJ+x15e+Gkpe9ICxMYYPVpVokpSYWJj4Oc/NzJ81hqvu3HM9qakcdkdA0hNTScQCNK2dT3u73IhL73/Ax9/O4XiiYUAePCW9pzTvJbH1UZWIBCkQ7eXKV0igYHPdmXBktU8+vJwUlLTiIuNoe89l1O/ZgWvy4y4vSlptOv2Cilp6QTSA1x0TgMevqWd12VlOJqvs+c6ZhYA5mVqusQ5t8KjciJm4OfjqVKhFDt37c1oW7N+CxOn/8lJpYp6WFnkXdWuKV2uaMkdfYZktN37zCc8ccfFnN6wKh9/O5nXh/zCQznoxRQJ/V77ipanVee13jeQmpbO3pQ0ANZu2MKkGYspWzL3b+ezW9an7blN6P/2lxltH3wyhisvPYtG9aoyY/YSPvxkDP0e68yYsTMA6P9sd7Zu20XfF4byQp+uxMTkniPxaQHHI98sYG96kNgY44VLajN95VZubXEK7//2N/PXbufcGiW4rH5ZhkxbRYvKxckTE8Ptw+aQLy6GNzvV49elyWzYkeJ1V45JvrxxDOt/O4UK5iMtPUDH7v1p3bQmAF2vPItbrznb4wqzz6B979m7Q+/Zz771DXfdcD6tm9Vk7JSFPPPWt3zW/w6Pq4y8fHnj+PrNHhQOb/MLb36ZNqfX4rRTT/G6NOAYzs6eS+xxztXP9G/F8azMzDwPiGs3bOWXyQu5ql2zA9r7vPYVD3fvgOWez4Gj0rxBFRKLFDygbenf62neoAoAZzWpwXfjZntQWfbZsWsv0+Yu44q2TQHImyeOIoVDI1pPvfENPW85MbZz7RoViC984EidmbFnT+iDfffuvRQrGjpF4KrVGzm1dujNMjGhEIUK5mfp8tw3+rE3PQhAXExo1AcHJyfmZ/7a7QDMWrWNMyoVCy3sHPnzxBBjkDc2hvSgY3dqwKvSj5uZUahgPgDS0wOkB4InxPP4SNZu2MovUxZyVftM79lmGSFo+869lCqe4FF12cvMKBze5mnpAdLSA1gO2uief6BHi5k1Al4m9BX9TUBn59xaM+sKdAPyAkuB/3PO7TazwcBmoAEwE7jPk8LDnhzwJY9078DO3fv3+sZMnE/ppARqVTnJw8qip0alMoyaMI8LW9bl219msXrDVq9LiqhVa5MpllCIB5//lD/+WkOdaifz2O2XMHnmEkolJVCzclmvS8w2N113Pn2eH8Lgj8fgnOOZJ24C4JTypZk680/ObF6HTcnb+GvFGpKTt0Hl3PWcjzHof3ldyiTk57v56/hzw07+3ryHZhWLMmXFFlpULk5S4dAHxcRlm2lasRhDbmhMvrgY3p20gp0p6R734PgEAkEu7PIiK1Zv4oaOLWhYuyJjpyxi8BcT+PzHadSrXo5ed1zyr52d3KzPa1/y8K0Hvmc/cUdHrn/gLZ5+4xuCzjHi9R4eVpi9AoEgrf7vOZb/s5EuV7SkcZ2KXpeU4UQd8SlgZrPD/740szzAAOBy51wjYCDwVHjZL5xzpznn6gGLgC6Z1lMNaOOc8zT0/PzbAooXjefU6uUy2vbsTeW1j8Zwb5cLPawsul559FoGjZjAuZ2fZ+fuFPLGxXpdUkQFAkEWLFnNNRedzjfv3EeB/Pl49YPRvDH0Z+7ufL7X5WWrH3+ezk3Xns97r97DTdeez+vvfgPAOWc1IKlYPPf3eof3h/xIjarliInNfW9bQQd3Dp/LDR/OoFrJwlQoVoBXxi6lXZ3S9L/8VArkjSU9GBoVqlayMEHn+L8PZ3DT0Jl0rF+W0vH5PO7B8YmNjWH04J5M+6I3sxet5I9la7m+YwsmfdaL0YMeoGTxBPq+9pXXZUbMz78toHjige/ZAEO+nkSvOy5h8udP0Ov2i3nw+U89qjD7xcbGMOHjh1nwXT9mLvibhUtzzkjtiTris8c5V3/fH2ZWB6gDjAkPt8UCa8NX1zGzfkAiodGgHzOtZ3j4RK0HMLNuhEaJOLlc+Wwo/0DT5y3np0nzGTdlISmp6ezYtZe7+w1l1drNXHjTCwCs3biNdje/xNdv30PJ4kWyvSYvVK1YimH9bwfgr5UbGDNpgccVRVbpEgmULpGQMdnxgpZ1GfDBj/yzbjMdur4EwLqN27jklv8x4o27KFHsxNnOYyfMocv/XQDA6U1r8fp7oeATGxvDTdddkLHcQ0++T9nSxT2pMRJ2pQaYu2Y7jcol8sWctfQauQiAsgn5Oa18aP5Wq6pJzFi1lUDQsW1POgvX7qBKycKsy6VzfDJLiC9I8wZVGDdl0QFze665qBmde77rYWWRNX3+cn76bT5jfw+9Z+/ctZe7+w3h598W8ESPjgC0a12fh174zONKs19CfEFaNKrKz5MXUqtKzhi1PlGDz8EMWOCca57FdYMJTX6eY2adgVaZrtuVxfI4594B3gGo37BRtv+K9YO3tOfBW9oDMHnWUt75dCxv97vxgGXOuLIP375z7wnzra6sbNy8gxLF4gkGg/xv0I/c0PEMr0uKqBLFilCmZCLLVm6gUvmSTJ65hFpVT+bDl7pnLNPq6n588dbdufpbXVkpWjSeBYv+pk6tisxbsJwy4XCTkpKGc478+fMye95fxMbEUO6kEh5X+98UyR9HIOjYlRogb2wM9U9O4PNZq0koEMe2PekYcFWjk/lh4ToANu5Iod5JCYxdvIl8cTHUKFWYr+euPfyd5GDJW3YSFxdDQnxB9qSkMnH6Ym679hzWb9pGqaTQHJdR4+dRvVIZjyuNnAe7tefBbvvfs9/9bCyvPHYd5/zfM0yZ/RfNG1Tht5lLqHhy7nouH61NW3aQJy42tM33pjJu6p/cdX0br8vK4Jfg8ydQwsyaO+cmhw99VXPOLQDigbXhtmuB1V4WKiG3PD6Y32YuZfPWndS/qBcP3NyWXXtSGDRiAgBtW9Xj6vbNjrCW3KfXnR257+mhpKUHKFemGM/2vMrrkiLupddGsGDRCrbv3M3Nd77MVZe14rYuHXj/o1EEg0Hy5Injti6hD41t23fx5HNDsBijeNF47ure0ePq/7tiBfNy79lViIkJTfqcuDSZaX9v5aJTS9O+TmkAflu2mTF/bARg5Px13HN2Fd7oVA8Dxvy5kRWbd3vYg+OzPnk79zw1lEAwiAs62p9dnzZn1KZH3yEsWLIaMyhXuhjPPnCl16Vmu2cf6MSTA74kPRAkX944nrn/xOzzuk3bua33RwSCQYJBR8c2DbngzFO9LiuDOXfinXbLzHY65wof1FYfeBVIIBT4XnHOvWtm3YGewN+EvgIf75zrHJ7cPNI59/nh7qt+w0Zu9K9TsqEXOVf+PCfW3JqjsX1PmtclRN38Ndu9LiHqXvhlqdclRN2wm07zuoSoSw+ceJ97R5JQMI/XJUTVGU0bM2PG9Cy/SnZCjvgcHHrCbbOBllm0vwm8mUV75+yoTURERLyT+74eISIiInKMFHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ34rwu4EQQF2NelxBVqelBr0uIunxx/ttHOL1yca9LiLphFYt6XULUtej3s9clRN0Xd7bwuoSo89t7WNAd+jp/PRIiIiLiawo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiGwo+IiIi4hsKPiIiIuIbCj4iIiLiG3FeFyBHtjcljcvuGEBKajqBQJB2retxf5cL6fv614yZtIC8eWKpUDaJlx+5moT4gl6XGxF7U9K4/M4BpIb73LZVPe7rciELl67m4ReHsWtPKuVKF+PVx/+P+EL5vS43YgKBIO27vUyppAQGP9eVkWNn879Bo1j69wa+eftu6tUo73WJEbV6/Rbu6PMRG5N3EBNjXHfx6XTr1Iot23bRrddgVq3dTLkyxXi3340kFjlxntuX3ZHpuR1+Pe/z1se/0O+Nb5g7sh/FEgt7WOnxizEY2r05G7bv5a4hswC4qml5OjUrTyDomPDnRvqPXkzTysXpcW5V8sTFkJYe5JUfFzNt+WaPq//ver8ynAlTF1EssTDD37gXgG07dvPQs0NZs2ELZUsW5bmHrqVIfEG+HzuLD0f8mnHbJSvW8XH/HlSvXNar8o/L6vVb6NF3CBs27yDGjOsubk7XK1sB8P7w8QwaMYHY2BjanF6LXrdf7GmtOS74mFkAmAfkAdKBD4BXnHNBM2sMXO+c65HNNVQETnfOfZyd93O08uWNY1j/2ylUMB9p6QE6du9P66Y1aXladR6+pT1xcbE89cY3vPbRTzx620VelxsR+fLG8dkr+/t86W39ad2sJr1eGcFjt11M8wZV+PS7Kbz1yS88cHNbr8uNmIGfj6dKhVLs2LUXgOqnlOGdfjfx8IvDPK4se8TFxvBkj47UrV6Onbv2cu6NL3BWk+p89t1UzmxcjR7Xn8urH45hwEdjPH+zjJRDvZ4b1anImvVbmDD9T04qVdTrMiPimuYVWL5xF4XyxQLQ+JRitKpZkitfm0RawFG0UF4Atu5O5e6hs9i4I4XKJQvzxg2NOP+FXw+36hypQ5tGdGp/Oo+//FlG26Dh42hSrwo3XtmaQcPGMmj4OO66qS1tWzegbesGACxZsZZ7+3yYa0MPhF7LT9x5ScZr+fwuL9LytBps2ryDHyfO4+cPHyRf3jg2bdnhdak58lDXHudcfedcbeBcoC3wBIBzbnp2h56wisA1Ubifo2JmFCqYD4D09ABpgSBmcFaTGsTFhd5QGtauyNqN27wsM6IO7nN6ehADlq3cQLP6lQFo2bg6P4yb42GVkbV2w1Z+nryQq9o1y2irWrEUlcuX9LCq7FUqKYG61csBULhQfqpWLMW6jdsYNWEendo2AaBT2yb8MH6el2VG1L+e2+HXM0DvAV/xaPeLMv7OzUoWyUeLaiX4cvo/GW1XNCnHoPHLSAs4ALbsSgXgz7U72LgjBYC/Nuwkb1wMeWJz34PQqE4lEuILHND265QFtG/TCID2bRoxbsqCf91u1K9zOP+selGpMbv867VcoRTrNm7lg68mcsd1bciXNzTOklQ03ssygZwZfDI45zYA3YA7LKSVmY0EMLOzzGx2+N8sM4s3sxgze8PMFpjZSDP73swuDy+/wsySwpcbm9m4Q60HeBY4M9x2jyedP0ggEOTczs9Tt8NjtGxcjYa1Kx5w/aff/U7rZjW9KS6bBAJBzr/xeepf9BhnnlaNBrUrUr1SGUZPnA/AyLGzWbNhq7dFRlDvAV/ySPcOxMTkvjf8SFi5Npn5i1fTsHYFNm7eQamkBCD0hpoT9hIjKRAIcl7n56nX4THODL+eR0+cT+mkBGpVPcnr8iLigbY16D96MUHnMtoqFC9Ig4pF+bBbU9676TRqnVTkX7drU7sUf67dkRGOcrvkrTspUSzUzxLFirB5665/LTNm/BwuOKt+lCvLPqvWJjNvyT80rF2RZSs38vucv2jb9WU63v4qsxf97XV5OTv4ADjnlhGq8+Dd3vuB251z9YEzgT3ApYRGa04FbgaaH8VdZLWeh4AJ4ZGn/x1/L45fbGwMYwb3ZPoXvZm1aCV/LFubcV3/D0YTFxvDpec18rDCyIuNjeHHQT2ZOqI3s8N9fvGhq/ngy4m07fIiu/akkCdPrNdlRsRPvy0gqWh8xh6T3+zanUKXh9+n792XEl+owJFvkMvFxsYwenBPpn0Rem4vXLqGVz8Yzf03X3jkG+cCZ1YrweadqSxas/2A9tgYo0j+PFz/zu/878fFPN/pwFGOSiUL0eO8avT7+t+jIieqeX+sJH++vFSpWNrrUiJi1+4Uujw6kD49LiW+UH7SAwG27djDd+/cw+O3X0y3XoNxzttQm+Pm+BxCVrvAk4CXzWwo8IVz7h8zawEMd84FgXVmNvYo1p3Veg5fjFk3QiNRnFwuupNNE+ILcnqDKoybsogalcow7Iep/PTbAob1v50j1Z1bJcQXpHmDKoz7fRG3Xn02H7/cHQgd9vp58kKPq4uM6fOWM2bSfMZOWUhKajo7du3lrr5D6N/rOq9Ly3Zp6QFueuR9Lju/Me1ahT4ISxSLZ/2mbZRKSmD9pm05Yng8O+x7bo+eOI9VazdzXufnAVi7cRsX3PQiI9+9l5LF/z0qktPVr5DIWTVK0qJaCfLGxVAoXxz9Lj+V9dtT+HnhegAWrN5G0EHRgnnYsjuNkkXy8fLVDeg1Yh7/bNnjcQ8ip3hiYTZu3k6JYkXYuHk7xRILHXD9j+Nz/2GufdLSA3R5dCCXnrf/tVymZCJtz6qLmdGgVgVizEjeuoukot5N3M/xIz5mVgkIABsytzvnniU0qlMAmGJmNcg6IO2Tzv7+ZnwN6BDrOSzn3DvOucbOucbFk5L+S3eOSfKWnWzbsRuAPSmpTJi+mMoVSjF2yiLeGPozg5/tSoH8ebO9jmjKqs9VypfKOOQRDAZ59cPRXHfx6V6WGTEP3dKeqSN689uwx3nties5vWFVX4Qe5xz3PPUxVSuU4tarz85oP79FHT77fioAn30/lQvOPNWrEiPu4Of2xOmLqVP1ZOaM7MeUz59gyudPUKZEAqMG3p8rQw/AgDFLuODFX2n38ngeGjaHacuTeezzeYxbtJ4mlYoDUL54QfLEGlt2p1E4fxwD/q8RA8YsYc7Krd4WH2Etm9Zi5E8zABj50wzOalY747pgMMhPE+dyfsvcH3ycc9z7zCeh1/JVrTPaLzjzVCbOWALAXys3kJYeoPhB4S/acvSIj5mVAN4CXnPOucwjGmZW2Tk3D5hnZs2BGsBE4AYz+wAoAbQC9n0zawXQCPgBuOwI61kF5JhdzPXJ27n7qaEEg0GCQUeHs+tz7hm1OaNTP1LS0rnqnjeA0ATn5x640uNqI2ND8nbueXoogUCQoHN0aF2fNmfU5v3hv/LBFxMBuPCsunRq29TjSrPXqPFzebz/F2zeupMbH3yXWlVOYshLt3pdVsRMnbuM4aOmUbNyWc6+/jkAHrm1PXdefy5dHx3Ex99O4aRSRXnvqRs9rjRy1idv556nhhIIBnFBR/uzQ89tP/hq5mp6d6zD8DtOJy3geHxEaL7eVU3LU65YAbq2qkTXVpUA6P7BjIzJz7nFw899zIx5y9i6fRcXXP8Ut157Ljde0YoHnx3KV2OmUbpEIs8/vH+HZub85ZRMSuDkMsU9rDoyps5dxuejplGzchna3BAauXz4lnZc3b4Z9zz9Ma2ue4Y8eeLo/9i1nh+dMK+PtR0si6+zfwS8HP46eyvgfudcezMbALQmNBq0EOgMpAFvAC2BxUC+8G3HmNmZwPvAeuB3oLFzrtUh1hMERgFJwODDzfOp37CR+2XC75F8CHK8YM56ykRFTnudREO+E2T+1H+RFgh6XULUtej3s9clRN0Xd7bwuoSoK5N44vze2dFo3aIps2ZOzzJh5bgRH+fcId9tnXPjgHHhy3dmtYyZ3e+c22lmxYGphEIUzrkJQLUs1pnleoBz/lPhIiIikuPluOATASPNLBHIC/R1zq3zuB4RERHJIU644OOca+V1DSIiIpIz5fhvdYmIiIhEioKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+IaCj4iIiPiGgo+IiIj4hoKPiIiI+Eac1wXkdsEgbN+T7nUZUVWiSD6vS4i63Sn+2sYAwaDzuoSoizHzuoSoG3b7GV6XEHWXvTbJ6xKibsKjZ3tdQlQ5Dv3+pREfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Q0FHxEREfENBR8RERHxDQUfERER8Y04rwuQI1u+agP39huS8feqdcncecP5zF74NytWbQRg+649FClUgC/fvterMiOqR9+hjJ40n6Si8Uz85BEAtmzbxc2PDWLlms2UL1uM95+6icQiBT2uNLICgSDtu71MqaQEBj/Xlafe+IaffltAnrhYKpyUxIsPXU1CfAGvy4yY1eu30KPvEDZs3kGMGddd3JyuV7bill6D+WvlBgC27dxDQuEC/PRBT4+rjYzV67dw10F9vvnKVixYspqHXhjGrj0pnFymGK8/cT3xhfJ7Xe4x69t/OBOn/UHRhMJ8+vo9ALw68HsmTF1EnjyxnFS6GI/fdQXxhUPP58HDx/LNmOnExBj3dbuI5g2reVn+MYsxGHJrMzZuT+GuobMA6NS0HJ2alicQdExcvJH+o5cAcOOZp3BJw5MIOMcL3//B5KXJXpZ+XPampHHZHQNITU0nEAjStnU97u9yIS+9/wMffzuF4omFAHjwlvac07yWp7XmyuBjZh2BL4Cazrk/vK4nu51SrmRGoAkEgrS6ui9tzqjDDZe2zFjmube+oXAufpM82FXtm9Llipbc/uRHGW39PxxDy8bVuOuG8+j/wWj6fziGJ+642MMqI2/g5+OpUqEUO3btBeDMxtV4sFs74uJiefrNb3l9yE880r2Dx1VGTlxsDE/ceQl1q5dj5669nN/lRVqeVoO3+3bOWKb3gC8pUujECXtxsTE8nqnPF4T7fP+zn/D4HZfQvEEVPhk5hTeH/kzPbu28LveYtTunEVe0O53e/xuW0dakfhVuu+F84mJjGTD4BwZ/Po47O1/IspXrGT1+Dp++fg8bk7dzR6/3+Pyt+4mNzX0HJa5uXoHlG3dROF/o47XxKUVpVaMknV7/jbSAo2ihvACcUqIQ559amstfm0SJ+Py82bkRHftPJOi8rP7Y5csbx7D+t1OoYD7S0gN07N6f1k1rAtD1yrO49ZqzPa5wv9z3rAq5GpgIXJWdd2JmOS4YTpm1hHJlinNSqWIZbc45Ro2fQ7vWDTysLLJOb1CFogeN5vwwfh6d2jUFoFO7pnz/61wvSss2azds5efJC7mqXbOMtpZNahAXFwtAw9oVWLdxq0fVZY9SSQnUrV4OgMKF8lO1QqkD+uic49tfZnPJuQ09qjDyDu5zlQqlWLtxK3+t3ECz+pUBaHladb77dY6XZR63hnUqUeSg0clmDasRFxt6PtepXo4Nm7YBMP73hZzXsh5588RxUulinFymOAuWrIp6zcerZJF8nFktia9mrM5ou/y0cgyasJy0QCjRbNmVCkCrGiX5cd460gKONVv38M/m3dQ5OcGTuiPBzChUMB8A6ekB0gNBzDwu6hByXfAxs8LAGUAXwsHHzFqZ2Tgz+9zM/jCzoWahh9zM2obbJprZq2Y2MtxeyMwGmtk0M5tlZheH2zub2XAz+xYY7U0vD+37cbNp17r+AW3T5y2jeGI8FU8u4U1RUbJx8w5KJ4XeGEonJbBpyw6PK4qs3gO+5JHuHYiJyfrd4rPvf6dVs5pRrip6Vq1NZt6Sf2hYu2JG25Q5f5FUNJ5K5Up6V1g2WrU2mfnhPlevVIYfJ84HYOTY2axZv9Xb4rLZt2Omc3qj6gBsTN5OqaTEjOtKJiWwMXm7R5Udu/svrEH/HxcTdPuHbSoUL0jDCkX5oFtT3r2pMbXKFgFCIWn9tr0Zy63ftpcS8bl71D4QCHJe5+ep1+ExzmxcLeO1PPiLCbS54Tnue/pjtm7f7W2R5MLgA1wCjHLOLQY2m9m+XcEGwN1ALaAScIaZ5QfeBi50zrUAMieDR4FfnHOnAa2BF8ysUPi65sANzrksx+bMrJuZTTez6cnJGyPbu8NITUvnl8kLOP+sege0fzf232FIcpeffltAUtH4jJGAgw34cAxxsbF0PLdRlCuLjl27U+jy6ED69Lj0gHktX42ZSccTaLQns127U7g5U59ffuQaBo+YwPk3vcDO3XvJmyfW6xKzzcDPfiE2NoYLWtUHQiN7B8uhgwWHdGa1JDbvSmXR2gN3yGJjYogvEMcN7/zOKz8u5rlOoffvrPrnyKXHucJiY2MYPbgn077ozexFK/lj2Vqu79iCSZ/1YvSgByhZPIG+r33ldZm5co7P1cAr4cufhv/+DpjqnPsHwMxmAxWBncAy59zy8PKfAN3Cl88DLjKz+8N/5wfKhy+Pcc5tPlQBzrl3gHcA6tZvFLVn6oRpf1CryskkFY3PaEsPBPhp4jw+f+PuaJXhmRLF4lm3aRulkxJYt2nbAY9Dbjd93nLGTJrP2CkLSUlNZ8euvdzVdwj9e13H8B+m8vPkBXzyv9uwnDp2fBzS0gN0eXQgl57XmHat9of69PQA3/86hx8HPuBhddkjLT3AzeE+tw33uWqFUnz6ym0A/LVyAz//ttDLErPNyJ9nMHHaH7zR7+aM53PJpATWb9qascyGTdtIKl7EowqPTb3yiZxVvQQtqiaRNy6GQvni6HdZHTZs38svC0MT9Res3k7QORIL5mH99hRKJewP+aUS8rNpR4pX5UdUQnxBmjeowrgpiw6Y23PNRc3o3PNdDysLyVUjPmZWHDgbeM/MVgAPAJ0IhefMz5gAoVB3uE8JAy5zztUP/yvvnFsUvm5XxIuPgKxGdibPXMIp5UpSukSiJzVF0wVnnspn3/0OwGff/c6FLU/1uKLIeeiW9kwd0Zvfhj3Oa09cz+kNq9K/13WM+30Rb378C+8/czMF8uf1usyIc85x7zOfULVCKW69qvUB142fvpgqFUpRtmSiN8VlE+cc94X7fEumPu87dBsMBun/wWj+75IzvCox20ye8ScfjfiVl3pdT/5Mz+czm9Ri9Pg5pKals3rdZlatSaZ21axHP3Oq135ayoUvjaf9/ybw8PC5TF++mcdGzGfsog2cVik0J7N88YLkiY1h6+40fv1jA+efWpo8sUbZxAKUK1aQ+f9s87gXxy55y0627QgdxtqTksrE8Ot3/ab9fRo1fh7VK5XxqsQMuW3E53LgQ+fcLfsazOxXoMUhlv8DqGRmFZ1zKwiFpH1+BO40szudc87MGjjnZmVX4cdrz95UfpuxmCfvvuyA9u9P0MNcXR8bxKSZS9m8dSentu/Fg93actcN59LlkYEM+WYKJ5cuysCnb/K6zGzX65UvSE1N59p73wSgQa0KPHP/lR5XFTlT5y7j81HTqFm5DG1ueB6Ah29pxzmn1+brn2ZySZsT7zDXofq8/J+NDP5iIgAXnlWXq8IT+XOrx174hBnzlrF1+y7ad36artecywefjyM1LZ07er0PQJ3q5Xn49o5UrlCKNi3q0um2l4mNjaHnrRfnym90ZeXrWavpfUltht1+OmmBIE98EZrHtWzjLsbMX8fnd55BIOh49rs/cu03ugDWJ2/nnqeGEggGcUFH+7Pr0+aM2vToO4QFS1ZjBuVKF+PZB7x//7Ksjq3mVGY2DnjWOTcqU1sPoDvwl3OufbjtNWC6c26wmXUAXgA2AVOBUs65a82sAKFDZqcTGv1Z4Zxrb2adgcbOuTuOpqa69Ru5b36aFKku5goliuTzuoSo252S7nUJUZfnBPng+S9yz7th5PyzeY/XJURdpzd+87qEqJvwaM75Onk0nHNmU2bPnJHlUZ9cNeLjnGuVRdurwKsHtWUOLWOdczXC3/J6HZgeXmYPcAsHcc4NBgZHrGgRERHJMfywS9c1PNl5AZBA6FteIiIi4kO5asTnWDjn/gf8z+s6RERExHt+GPERERERARR8RERExEcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDcUfERERMQ3FHxERETENxR8RERExDfivC4gtws6R2p60OsyomrhP9u9LiHqqpeN97qEqHPOeV1C1OXPE+t1CVFXrlgBr0uIugmPnO11CVHXadA0r0uIqmWbdh/yOo34iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG8o+IiIiIhvKPiIiIiIbyj4iIiIiG/EeV2AHJ2hX01kxKjfcQ4uu6AJ13U8kz/+WkO/AV+QmpZGbGwMj9zekVOrl/e61GP27Osj+G36nxRNKMQHr9x1wHWffD2BNz8cxTeDHiGxSCEA/lqxjhff/opdu1OwGOOd57qTL28eL0qPiNXrt3BHn4/YmLyDmBjjuotPp1unVmzZtotuvQazau1mypUpxrv9biSxSEGvy42I1eu3cGffIWxM3oHFGP93UXO6dmrFc+98x6gJ84iJiSEpsTD9H7uW0iUSvC434u7oM4QfJ84nqWg8kz971OtyssXq9Vvo0XcIGzbvIMaM6y5uTtcrWzF/8T88+MIwUlLTiY2N4dn7r6BBrQpelxsRe1PSuOzOAaSmphMIBGnbqh73d7mQ7k8M5q+VGwDYvnMPRQoXYPSgnh5Xe+zyxBrPXVyHPDFGTIwxaVkyH0//h1OKF+T2MyuRP08sG3bs5YWfl7InLUCrqklcWq9sxu0rFi/IXZ/PZXny7qjWHbXgY2algVeA04AUYAVwt3Nu8X9cz93AO865bH2kzOwR59zT2XkfR2vJinWMGPU7Q1+5kzx5Yrntsfc5s0kN/vf+d9x6bRtanFaDCVMX8cr73/P+87d6Xe4xu6BVQzpe2IynX/38gPb1m7Yyfc5SSiUlZrSlBwL07T+Mx+66gioVy7Btx27iYmOjXHFkxcXG8GSPjtStXo6du/Zy7o0vcFaT6nz23VTObFyNHtefy6sfjmHAR2PodfvFXpcbEXGxMfS+85KMPp9304u0bFKD2649hwe7tQPgvWG/8vKgUTzfs5PH1Ube1e2b0fXKs7j1iQ+9LiXbxMXG8ESmbXx+lxdpeVoN+r7xDffedAHnNK/Fz78toO8b3/DFa3d6XW5E5Msbx7BXbqdQwXykpQfoeFt/WjeryZtPds5Yps9rXxFfKL93RUZAWsDxyDcL2JseJDbGeP7i2sxYuZVbWpzCwMl/M3/tds6tXoLL6pdlyLRVjFuyiXFLNgFQoVhBel1QPeqhB6J0qMvMDPgSGOecq+ycqwU8ApQ6htXdDURjd/eRKNzHUVm+agN1a5SnQP68xMXG0ujUSvzy2wLMjJ279wKwc/deShQv4nGlx6d+7VMoUvjfm/a1Qd/T/foLMNvfNm32UipXLE2VimUASIgvSGxs7j5yWyopgbrVywFQuFB+qlYsxbqN2xg1YR6d2jYBoFPbJvwwfp6XZUbUv/pcoRTrNm494ANh995UDtj4J5AzGlah6Akyencoh9rGZsbOXaH3r+279lI6KXe/f2VmZhQqmA+A9PQA6elBMj+DnXN8O3Y2F7dp5E2BEbQ3PQhAXIwRG2M44OTE/Mxfux2AWf9s4/RTiv3rdmdVKc6vSzdFs9QM0RrxaQ2kOefe2tfgnJttIS8AFwIO6Oec+8zMWgG9gU1AHWAGcB1wJ1AWGGtmm5xzrc3sPOBJIB/wF3Cjc26nma0APg7fdx6gG/AMUAV4wTn3Vvh++gDJQHVgPHAb8DRQwMxmAwucc9dmz8NydKpUKMWAD0axdfsu8uXNw8Rpf1Cr6sn0vKUD3R97n5ff+46gc3z40u1elpktJk5bRFKxIhkBZ59VazdhGPf1GcTW7bs4p0VdrrmkpUdVRt7KtcnMX7yahrUrsHHzDkolhQ7zlEpKYNOWHR5Xlz1Wrk1m/pJ/aFi7IgDPvDWS4aOmEV8oPyNOkJEAv1u1Npl54W3c566OXH3vm/R5/WuCQcc3b9/tdXkRFQgEufDmF1mxehM3dGyR8bwG+H3OMkoUjadSuRLeFRghMQavXFaXMgn5+W7+OhZv2Mnfm/fQtGJRfl+xhRaVi5NUON+/bndm5ST6jfrDg4qjN7l5X3g52KVAfaAe0AZ4wcz2fcI1IDS6UwuoBJzhnHsVWAO0DoeeJOAxoI1zriEwHbg30/pXOeeaAxOAwcDlQDNCYWefJsB9wKlAZeBS59xDwB7nXP2sQo+ZdTOz6WY2fUty9ifWSuVLceMVrbjlkXe5rdf7VKtUhrjYGIZ9N4UHunVg9EeP8kC3DvR+ZXi21xJNe1NS+WjEOLpc1eZf1wUCQeb+8Te97r6S15/qxoTfFzJj7l8eVBl5u3an0OXh9+l796XEFyrgdTlRsWt3Cjc/MpA+d12aMdrz8K3tmfnVk1x2fmMGjhjvcYVyvHbtTqHLowPp0yO0jT/8chJP3tmRGV8+yZM9OnLfM594XWJExcbGMHpQT6aN6M3sRSv5Y9najOu+/mkGF7dp6GF1kRN00OPzuXT+aAbVShamQtEC9B+3lHa1S/PKZadSIE8s6cHgAbepVrIwKelB/t6yx5OavT420AL4xDkXcM6tB34lNAcIYKpz7h/nXBCYDVTM4vbNCAWjSeHRmRuAzLPjvgn/Pw/43Tm3wzm3EdhrZomZ7meZcy4AfBKu6bCcc+845xo75xoXLZ509L09Dpee34TPXrubQS90JyG+IOVPSuLbn2Zwzhl1ADjvzLrM/3NVVGqJltXrNrN2/RZuum8AV976AhuTt3PzA6+TvGUHJYsnUL9WRRKLFCJ/vrw0a1iNxcvWeF3ycUtLD3DTI+9z2fmNadeqHgAlisWzftM2ANZv2kZS0XgvS4y4tPQAXR4ZyKXn7e9zZh3PbcR3Y+d4UJlESlp6gC6PHriNh/0wNeNyh7PrM2vh316WmG0S4gvSvEEVxv2+CAgd+vph/Fw6nN3A48oia1dqgHlrttOwfCL/bN3L498t4u4R8/h16SbWbU85YNmWHh7mgugFnwVAVgczD3fgPvMjFSDrw3IGjAmPzNR3ztVyznXJYh3Bg9YXzLQ+d9A6D/47R0jeuhOAtRu28POk+Vx4Vn1KFC/C9HnLAJg6eynlT4pOCIuWyhVK882gRxj21gMMe+sBShQvwnsv3E7xovE0qV+Vv/5ex96UVNIDAWYvWEHFXD5s7Jzjnqc+pmqFUtx69dkZ7ee3qMNn308F4LPvp3LBmad6VWLEOee45+lPqFqxFLde3TqjfdmqDRmXf5w4nyoVjmU6oOQEzjnufeaT0PP6qv3buFRSApNnLQVg4ozFnJLLX7+ZJW/ZybYdoUm7e1JSmTh9MVXKh57DE2YspnL5UpQtmehhhZFRJH8chfKGvlSSNzaG+icn8M+WPSTkD328GnBVw5P5YcG6jNsY0KJSccZ7GHyiNcfnF+BpM+vqnHsXwMxOA7YAnczsA6AY0BJ4AKhxmHXtAOIJzf+ZArxuZlWcc0vNrCBw8n/8plgTMzsF+BvoBLwTbk8zszzOubT/sK5sc1+/D9m2fTdxcbE8ctslFIkvyOM9LuP5t78hEAiSN28cj/e4zOsyj8uTL3/GrAXL2LZjN5d1fY4bO51D+zaNs1w2vnABOnVoQbeeb2IGzRpWp3mjwz1tcr6pc5cxfNQ0alYuy9nXPwfAI7e2587rz6Xro4P4+NspnFSqKO89daPHlUbO1LnL+HzUNGpWLsM5NzwPwMO3tOOTkVNY+vcGYmKMk0sX4/meV3pcafbo8uggJs1YQvLWndRu9xgPdWvL/118utdlRVTmbdwm0zZ+8cFO9Or/BYFAkHx58/BCz6s8rjRy1idv556nhxIIBHHO0b51fdqcURuAb36aySUnyGGuYgXzcs/ZVYgxiDFjwl/JTFu5lYtOLU272qUB+G35Zsb8uTHjNnXKFmHTrlTW70g51GqznTkXnQEOMytL6OvsjYC9hL/OTmjScVaTm+93zrUP3/Y1YLpzbrCZ3QncDqwNz/M5G3iO0ORmgMecc9+EJzc3ds5tMrPO4ct3hNe3AmhMaO7R48BGQnN8xgO3OeeCZvYccBEw83CTm+vUa+i++HHicT8+ucm23TkiC0ZV9bIn1uGloxGt94acJF+e3P2TCMdib2rA6xKiLhD033O70+BpXpcQVVOfv4ntKxdleVQpasEnJzo4YB0LBR9/UPDxBwUff1DwOfEdLvh4PblZREREJGp8fcoK59w4YJzHZYiIiEiUaMRHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHzDnHNe15CrmdlG4G+P7j4J2OTRfXvFb332W39BffYL9dkfvOpzBedciayuUPDJxcxsunOusdd1RJPf+uy3/oL67Bfqsz/kxD7rUJeIiIj4hoKPiIiI+IaCT+72jtcFeMBvffZbf0F99gv12R9yXJ81x0dERER8QyM+IiIi4hsKPh4wM2dmL2X6+34z632M60o0s9uO8bYrzCzpWG57iPXtPOjvzmb2WqTWn2m935tZYqTXGylm9qiZLTCzuWY228yaHuXtKprZ/OyuLzsca5+P4X5y9LY/mJkFwo/Hvn8Vva7peGXq0wIzm2Nm95pZTPi6xmb2ahRqqGhm12T3/Ryhho7h9/IaXtYRCWZW2sw+NbO/zGxh+HVW7RjWc7eZFcyOGg+6n0eO5/YKPt5IAS6NUOhIBLIMPmYWG4H15zjOubbOua1e15EVM2sOtAcaOufqAm2AVd5Wlb2Op89mFneUy5mZxeTkbX8Ie5xz9TP9W3E8Kzvaxyub7etTbeBcoC3wBIBzbrpzrkcUaqgIeBp8gKuBicBV2Xkn2b3NzcyAL4FxzrnKzrlawCNAqWNY3d1AtgcfQvUdMwUfb6QTmvB1z8FXmFkJMxthZtPC/84It/c2s/szLTc/vPf4LFA5vAf2gpm1MrOxZvYxMC+87FdmNiO8h9YtGh3Mol8dzOx3M5tlZj+ZWalM/frIzH4xsyVm1jXc3srMxpvZl+E9kLcy7VWuMLOk8F7fIjN7N9y30WZWILxMZTMbFe73hH17ZWZ2Rfixm2Nm48Nttc1savgxnGtmVY+jq2WATc65FADn3Cbn3Bozezy8Peeb2TvhNxvMrFG4lsnA7Zker85m9kW4D0vM7PlM151nZpPNbKaZDTezwuH2Z8OP1Vwze/FQ/c0Gh+pzxohieCRgXPhy7/BjMBr4MNzXr8N9/dPMnggvt2/7vgHMBMpl2vaFzOy7cL/mm1mnTI/nr+Ht/qOZlcmmPh+zQ9VoZl3Dz5E54feAguH2wWb2spmNBZ7ztPiDOOc2AN2AOyyklZmNBDCzs2z/SNcsM4s3sxgzeyP8eh1poZGFy8PLH+r58q/1EHrfOzPc9q/30ewWfs2dAXQhHHzCfR9nZp+b2R9mNjTT67xtuG2imb2a6TEqZGYDw9t9lpldHG7vHH5tfwuMzubutAbSnHNv7Wtwzs0GJlroM2W+mc3L9BrLsp9m1gMoC4wNP1cP9161wsyeDl833cwahl8Lf5nZrZnu51+fAWb2LFAgvO2HHlOPnXP6F+V/wE6gCLACSADuB3qHr/sYaBG+XB5YFL7cG7g/0zrmE9rrqQjMz9TeCtgFnJKprVj4/wLh2xUP/70CSIpgvwLA7Ez/VgKvha8ryv7J9DcDL2Xq15xwbUmERgrKhvuxF6gExAJjgMsz1x3uezpQP9w+DLgufPlnoGr4clPgl/DlecBJ4cuJ4f8HANeGL+cFChzHY1A43PfFwBvAWZm3QfjyR0CH8OW5mZZ5Yd+2BDoDy8LPj/yEfh28XLjf44FC4eUeBB4HigF/ZnqMEw/V32x4Ph+qzxnPL6AxoT3Kfdt8xr7HOdzXtUBx9j9HG4e3bxBolum+9m37y4B3M7UnAHmA34AS4bZOwECPX+uZXxNfHq5Gwq/L8OV+wJ3hy4OBkUCsl33JVNvOLNq2EBohaAWMDLd9C5yR6TkSB1wOfE9op7t0+HYHvK6zeL5ktZ6M+/HoMbgOeD98+TegYbimbcDJ4f5NBloQev2uIvyeDHyS6TF6mv3vWYnh11Ch8GviHzK9b2RjX3oA/8ui/TJC77ux4W27ktBOTpb9zGIbZvlelWm57uHL/yP0PhgPlAA2hNtbcejPgH89B//Lv5wwbOpLzrntZvYhoSfdnkxXtQFqhXcUAIqE93D+i6nOueWZ/u5hZh3Dl8sBVYHkYyj7SPY45+rv+8PMOhN6A4PQi+Sz8N5tXiBzfV875/YAe8J7Ck2AreF+LAuv6xNCbyKfH3Sfy11o7wRCH6YVw3sVpwPDMz2O+cL/TwIGm9kw4Itw22TgUTM7GfjCObfkmHoPOOd2mlkj4ExCe1KfmdlDwA4z60loGLgYsMBCIzCJzrlfwzf/CLgw0+p+ds5tC/d/IVCB0JtjLWBSuG95w/VvJ/Qm8Z6ZfUfog/JQ/Y2ow/T5cL4Jb/N9xjjnkgHM7AtC2/or4G/n3JQsbj8PeNHMniP0ITLBzOoAdYAx4ccmllCg8tLBr4nD1VjHzPoR2saFgR8zrWe4cy4QjYKPkWXRNgl4ObxX/oVz7h8za0GoL0Fg3b6RgSPIaj2Rq/zYXA28Er78afjv7wi9Z/0DYGazCYX3ncCyTO/JnxAaJQM4D7jI9o/m5ye0wwuh18Tm7OvCEbUAPgk/79ab2a/AaYTea7Lq58SDbt+MrN+r9vkm/P88oLBzbgeh98m9tn8e39F8BvxnCj7eeoXQEP6gTG0xQPODPhQws3QOPDSZ/zDr3ZXpdq0Ihanmzrnd4eHjw902uwwAXnbOfROuqXem6w7+TQV3hPbMUjJdDhAaMYgBtmb+wMlYgXO3WmjibTtgtpnVd859bGa/h9t+NLObnXO/HFWvshB+oxgHjDOzecAtQF2gsXNulYUmsucn9GFxuN+TOLhvceHbjHHOXX3wwmbWBDiH0ND7HcDZh+hvxENvFn2+gdBo3L7n7MHPuV0H/X2obX3wcvvub3E4bLUFnrHQYbMvgQXOuebH1InoMA5d42DgEufcnPBOQ6tM12X5OOQEZlaJ0PNzA1BzX7tz7tlwCG8LTDGzNmQdkPbJ8vlyiPV4xsyKA2cTCqqOUHh1hEayDvWaPeTqgMucc38edB9Nid42X0BoJO5gh6s7q35mdfss36sOWkfwoPUFM63vaD4D/jPN8fFQOM0PI3SceJ/RhD60ADCz+uGLKwgNp2JmDYFTwu07CA0RHkoCsCUcemoQSuFeSABWhy/fcNB1F5tZ/vAbSitgWri9iZmdYqG5PZ349x5Flpxz24HlZnYFZEyMrRe+XNk597tz7nFCJ84rF37jXuace5XQXkjdY+2kmVW3A+cI1Sd0CApgU3g06vJwnVuBbeG9YIBrj+IupgBnmFmV8P0VNLNq4fUmOOe+JzTBsP6h+nusfTuUQ/T5b0LP2UbhtsuOsJpzzayYheZoXUJoL/9w91kW2O2cGwK8SOi18SdQwkKTrTGzPGZW+7/1JtsdrsZ4YK2Z5eHongueM7MSwFuEDmm7g66r7Jyb55x7DpgO1CD0Gr4sPFdj36GxfVaQxfPlEOs50vtedroc+NA5V8E5V9E5V47QCHaLQyz/B1DJ9n+jr1Om634E7jTLmAvUIJtqPpxfgHwWnl8ZruM0QochO5lZbHg7twSmHmFdmbdLlu9V/7G2Q30GpIVfJ8dEwcd7LxE6FrpPD6CxhSaoLgRuDbePAIqFhxW7EzoWTHjvfZKFJqC9kMX6RwFxZjYX6EvoyeiF3oQOPU3g32fqnUpomHgK0Nc5tybcPpnQJMb5hN5YvvwP93ct0MXM5hDao7k43P6ChSbqzSd0/HkOoRfU/PBjWwP48L917QCFgQ8sPMmY0FBvb+BdQkO6X7E/2AHcCLxuocnNezgC59xGQsf/Pwmvf0q45nhgZLjtV/ZPnM+qv5F2qD4/CfQPb/MjHaaZSOhQ32xghHNu+hGWPxWYGt5mjwL9nHOphD6Ungtv99mEDnnmGEeosRfwO6G5DH94UuDR2TexdAHwE6GdtSezWO7u8PvSHELP7R8IvY/9Q+g1/Tah/m4LL3+o50tW65kLpFtoIni0Jzdfzb/fi0ZwiG+ZhUfvbwNGmdlEYD37+9yX0LyvueHXaN9sqfgwwoG1I6Gdj7/C27U3ofmmcwm9Z/wC9HTOrTvC6t4BfjCzsYd5r/ovDvUZ8A6hx+yYJjfrl5vFU+HDPjudcy8e1N6K0GTu9h6UJVEUPqzT2Dl3x5GWldzPzAqH54UVJ7TTc8ZRfKDmapn6bMDrwBLn3P+8risny87PAM3xERGRaBppocmreQmN8J7QoSesq5ndQKjPswiNdolHNOIjIiIivqE5PiIiIuIbCj4iIiLiGwo+IiIi4hsKPiLiGdt/pu/5FjqXzzGf4NBC57Tad96n98ys1mGWbWVm//mr7pbpfFJH037QMjv/430dcH4+EYkMBR8R8dK+M33XAVLZ/7tVAJhZ7LGs1Dl3s3Nu4WEWaUUO+40fEYkOBR8RySkmAFXCozFjzexjYF74l2NfsNAZrOea2S2Q8Yvcr4V/OPE7oOS+FVno7NGNw5cvsNDZoeeY2c/hX9C9FbgnPNp0ppmVsNAZ0aeF/50Rvm1xMxttoTNnv83hf8Z/331/ZaEzry8ws24HXfdSuJafw7+Gi5lVttCZ6WeY2QQL/cK6iGQT/Y6PiHjOzOIInaB1VLipCVDHObc8HB62OedOM7N8hH6pfDTQAKhO6FecSwELgYEHrbcEoV/NbhleVzHn3GYze4tMP5wZDln/c85NNLPyhE4lUBN4ApjonOtjZu3Yf3LJw7kpfB8FgGlmNiL8C+uFgJnOufvM7PHwuu8g9Cu0tzrnlljoHE1vEDoXlIhkAwUfEfFSgfBpJyA04vM+oUNQUzOdzfo8oO6++TuEzvtWldC5g/adPXqNmWV1YtlmwPh96zrM2a7bALVs/1m/i5hZfPg+Lg3f9jsz23IUfephZh3Dl8uFa00mdPLFz8LtQ4AvLHSOtdMJnc5l3+3zHcV9iMgxUvARES/tcc7Vz9wQDgCZz0xtwJ3OuR8PWq4tRz5bsx3FMhA67N88fF6lg2s56l95Df/Mfpvwunab2Tj+fWb6fVz4frce/BiISPbRHB8Ryel+BLpb+GzMFjobfSFCJ129KjwHqAzQOovbTgbOMrNTwrctFm4/+OzeowkddiK8XP3wxfGEz5RuZhcCRY9QawKwJRx6ahAacdonhtAJSiF0QsuJzrntwHIzuyJ8H2Zm9Y5wHyJyHBR8RCSne4/Q/J2Z4TNYv01otPpLYAmhs96/Seis9AcInyG6G6HDSnPYf6jpW6DjvsnNQA+gcXjy9EL2f7vsSaClmc0kdMht5RFqHQXEWehs1H0JnZF6n11AbTObQWgOT59w+7VAl3B9C4CLj+IxEZFjpHN1iYiIiG9oxEdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfEPBR0RERHxDwUdERER8Q8FHREREfOP/AXr/kDgRAJOLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset_used != \"FER\":\n",
    "    labels=list(class_to_idx.keys())\n",
    "    print(labels)\n",
    "    IC = type('IdentityClassifier', (), {\"predict\": lambda i : i, \"_estimator_type\": \"classifier\"})\n",
    "    def plt_conf_matrix(y_true,y_pred,labels):\n",
    "        print(y_pred.shape,y_true.shape, (y_pred==y_true).mean())\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        plot_confusion_matrix(IC, y_pred,y_true,display_labels=labels,cmap=plt.cm.Blues,ax=ax,colorbar=False) #,normalize='true'\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    plt_conf_matrix(y_val,y_pred,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1b52415",
   "metadata": {},
   "source": [
    "## Number of parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94a498ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7712266"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9112d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2c8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
